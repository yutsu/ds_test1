#!/usr/bin/env python3
"""
Deep Research Clone - æ”¹å–„ç‰ˆ
è¨€èªãƒ¢ãƒ‡ãƒ«ã¨Webæ¤œç´¢ã‚’çµ„ã¿åˆã‚ã›ãŸç ”ç©¶æ”¯æ´ãƒ„ãƒ¼ãƒ«
ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹è¿½åŠ æ¤œç´¢æ©Ÿèƒ½ä»˜ã
"""

import os
import json
import requests
from typing import List, Dict, Optional, Set, Union
from dataclasses import dataclass
from pathlib import Path
import markdown
from dotenv import load_dotenv
import re
import yaml
from datetime import datetime, timedelta
import time
import random
from pydantic import BaseModel, Field, validator
from urllib.parse import quote_plus
from bs4 import BeautifulSoup

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

@dataclass
class SearchResult:
    """æ¤œç´¢çµæœã‚’æ ¼ç´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    title: str
    url: str
    snippet: str
    search_query: str  # ã©ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã§å–å¾—ã•ã‚ŒãŸã‹
    date_info: Optional[str] = None  # æ—¥ä»˜æƒ…å ±
    reliability_score: float = 1.0  # ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0.0-1.0ï¼‰
    source_type: str = "unknown"  # æƒ…å ±æºã‚¿ã‚¤ãƒ—ï¼ˆofficial, news, academic, blog, etc.ï¼‰

@dataclass
class Citation:
    """å¼•ç”¨æƒ…å ±ã‚’æ ¼ç´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    source_title: str
    source_url: str
    content: str
    search_query: str
    relevance_score: float = 1.0
    date_info: Optional[str] = None  # æ—¥ä»˜æƒ…å ±

@dataclass
class ResearchResult:
    """ç ”ç©¶çµæœã‚’æ ¼ç´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    query: str
    search_results: List[SearchResult]
    analysis: str
    summary: str
    citations: List[Citation]
    additional_queries: List[str]
    final_report: str

class Config:
    """è¨­å®šç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, config_path: str = "config.yaml"):
        self.config_path = config_path
        self.config = self._load_config()

    def _load_config(self) -> Dict:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        if os.path.exists(self.config_path):
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                # ç’°å¢ƒå¤‰æ•°ã‚’å±•é–‹
                self._expand_env_vars(config)
                return config
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
            default_config = {
                'language_model': {
                    'default': 'ollama',
                    'ollama': {'model_name': 'llama2', 'base_url': 'http://localhost:11434'},
                    'openai': {'model': 'gpt-3.5-turbo', 'max_tokens': 2000, 'temperature': 0.7},
                    'gemini': {'model': 'gemini-2.0-flash', 'temperature': 0.7}
                },
                'iteration': {
                    'max_iterations': 3,
                    'initial_search_count': 8,
                    'additional_search_count': 5,
                    'max_additional_queries': 3
                },
                'search': {
                    'engine': 'google',
                    'max_results': 5,
                    'rate_limit': {
                        'requests_per_second': 8,
                        'max_retries': 3,
                        'retry_delay_base': 2
                    },
                    'google': {
                        'api_key': os.getenv('GOOGLE_SEARCH_API_KEY'),
                        'search_engine_id': os.getenv('GOOGLE_SEARCH_ENGINE_ID')
                    }
                },
                'citations': {
                    'auto_extract': True,
                    'relevance_threshold': 0.5,
                    'reliability_threshold': 0.3,
                    'format': 'numbered'
                },
                'output': {
                    'format': 'markdown',
                    'directory': './output',
                    'filename_template': 'research_{query}_{timestamp}',
                    'markdown': {
                        'include_search_results': True,
                        'include_analysis': True,
                        'include_summary': True,
                        'include_final_report': True,
                        'include_citations': True,
                        'include_search_history': True
                    }
                }
            }
            return default_config

    def _expand_env_vars(self, obj):
        """è¾æ›¸å†…ã®ç’°å¢ƒå¤‰æ•°ã‚’å±•é–‹"""
        if isinstance(obj, dict):
            for key, value in obj.items():
                if isinstance(value, str) and value.startswith('${') and value.endswith('}'):
                    # ${VAR_NAME} å½¢å¼ã®ç’°å¢ƒå¤‰æ•°ã‚’å±•é–‹
                    env_var = value[2:-1]  # ${} ã‚’é™¤å»
                    expanded_value = os.getenv(env_var, value)
                    if expanded_value != value:
                        print(f"ğŸ”§ ç’°å¢ƒå¤‰æ•°ã‚’å±•é–‹: {env_var} = {expanded_value[:10]}...")
                    else:
                        print(f"âš ï¸  ç’°å¢ƒå¤‰æ•°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {env_var}")
                    obj[key] = expanded_value
                elif isinstance(value, (dict, list)):
                    self._expand_env_vars(value)
        elif isinstance(obj, list):
            for item in obj:
                if isinstance(item, (dict, list)):
                    self._expand_env_vars(item)

    def get(self, key: str, default=None):
        """è¨­å®šå€¤ã‚’å–å¾—"""
        keys = key.split('.')
        value = self.config
        for k in keys:
            if isinstance(value, dict) and k in value:
                value = value[k]
            else:
                return default
        return value

class LanguageModel:
    """è¨€èªãƒ¢ãƒ‡ãƒ«ã®æŠ½è±¡ã‚¯ãƒ©ã‚¹"""

    def generate(self, prompt: str) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ"""
        raise NotImplementedError

    def generate_structured(self, prompt: str, response_model: BaseModel) -> BaseModel:
        """æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ"""
        # æ§‹é€ åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
        structured_prompt = self._create_structured_prompt(prompt, response_model)

        # é€šå¸¸ã®ç”Ÿæˆã‚’å®Ÿè¡Œ
        response_text = self.generate(structured_prompt)

        # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æŠ½å‡ºã—ã¦ãƒ‘ãƒ¼ã‚¹
        try:
            json_data = self._extract_json_from_response(response_text)
            return response_model(**json_data)
        except Exception as e:
            print(f"âš ï¸  æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è§£æã«å¤±æ•—: {e}")
            print(f"   ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response_text[:200]}...")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
            return self._create_fallback_response(response_model)

    def _create_structured_prompt(self, prompt: str, response_model: BaseModel) -> str:
        """æ§‹é€ åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ"""
        schema = response_model.model_json_schema()

        structured_prompt = f"""
{prompt}

é‡è¦: ä»¥ä¸‹ã®JSONã‚¹ã‚­ãƒ¼ãƒã«å¾“ã£ã¦ã€æ­£ç¢ºãªJSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
ç•ªå·ã‚„è¨˜å·ã€èª¬æ˜æ–‡ã¯å«ã‚ãšã€ç´”ç²‹ãªJSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

JSONã‚¹ã‚­ãƒ¼ãƒ:
{json.dumps(schema, ensure_ascii=False, indent=2)}

å›ç­”ä¾‹:
{self._generate_example_response(response_model)}

JSONå›ç­”:
"""
        return structured_prompt

    def _generate_example_response(self, response_model: BaseModel) -> str:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ä¾‹ã‚’ç”Ÿæˆ"""
        if response_model == AdditionalQueriesResponse:
            return json.dumps({
                "keywords": ["å¸‚å ´è¦æ¨¡ çµ±è¨ˆ", "AIè¦åˆ¶ æ³•å¾‹", "å€«ç†ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³", "é›‡ç”¨å½±éŸ¿ èª¿æŸ»", "åŒ»ç™‚AI å¿œç”¨"]
            }, ensure_ascii=False, indent=2)
        elif response_model == AnalysisResponse:
            return json.dumps({
                "main_facts": ["2024å¹´ã«AIæŠ€è¡“ãŒå¤§å¹…ã«é€²æ­©ã—ãŸ", "å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãŒå‘ä¸Šã—ãŸ"],
                "data_statistics": ["å¸‚å ´è¦æ¨¡ã¯å‰å¹´æ¯”30%å¢—åŠ ", "ä¼æ¥­å°å…¥ç‡ã¯60%ã«é”ã—ãŸ"],
                "different_perspectives": ["æŠ€è¡“çš„é€²æ­©ã‚’è©•ä¾¡ã™ã‚‹æ„è¦‹", "é›‡ç”¨ã¸ã®å½±éŸ¿ã‚’æ‡¸å¿µã™ã‚‹æ„è¦‹"],
                "date_analysis": ["2024å¹´ã®æƒ…å ±ã¯æœ€æ–°", "2023å¹´ã®ãƒ‡ãƒ¼ã‚¿ã¯éå»ã®æƒ…å ±"],
                "unknown_points": ["å…·ä½“çš„ãªè¦åˆ¶å†…å®¹", "é•·æœŸçš„ãªå½±éŸ¿ã®è©³ç´°"]
            }, ensure_ascii=False, indent=2)
        elif response_model == SummaryResponse:
            return json.dumps({
                "key_facts": ["AIæŠ€è¡“ãŒ2024å¹´ã«å¤§å¹…é€²æ­©", "ä¼æ¥­å°å…¥ãŒåŠ é€Ÿ", "è¦åˆ¶è­°è«–ãŒæ´»ç™ºåŒ–"],
                "conclusion": "AIæŠ€è¡“ã¯æ€¥é€Ÿã«ç™ºå±•ã—ã¦ã„ã‚‹ãŒã€è¦åˆ¶ã‚„å€«ç†é¢ã§ã®èª²é¡Œã‚‚å­˜åœ¨ã™ã‚‹",
                "date_summary": "2024å¹´ã®æœ€æ–°æƒ…å ±ã‚’ä¸­å¿ƒã«æ§‹æˆ"
            }, ensure_ascii=False, indent=2)
        else:
            return "{}"

    def _extract_json_from_response(self, response_text: str) -> dict:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰JSONã‚’æŠ½å‡º"""
        # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¢ã™
        json_start = response_text.find('{')
        json_end = response_text.rfind('}') + 1

        if json_start == -1 or json_end == 0:
            raise ValueError("JSONãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        json_str = response_text[json_start:json_end]

        # è¤‡æ•°ã®JSONãƒ–ãƒ­ãƒƒã‚¯ãŒã‚ã‚‹å ´åˆã¯æœ€å¾Œã®ã‚‚ã®ã‚’ä½¿ç”¨
        if json_str.count('{') > 1:
            # ãƒã‚¹ãƒˆã•ã‚ŒãŸJSONã‚’å‡¦ç†
            brace_count = 0
            start_pos = -1
            for i, char in enumerate(json_str):
                if char == '{':
                    if brace_count == 0:
                        start_pos = i
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    if brace_count == 0 and start_pos != -1:
                        json_str = json_str[start_pos:i+1]
                        break

        # JSONã‚¨ã‚¹ã‚±ãƒ¼ãƒ—æ–‡å­—ã‚’é©åˆ‡ã«å‡¦ç†
        try:
            # ã¾ãšé€šå¸¸ã®JSONãƒ‘ãƒ¼ã‚¹ã‚’è©¦è¡Œ
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            # ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—æ–‡å­—ã®å•é¡ŒãŒã‚ã‚‹å ´åˆã€æ‰‹å‹•ã§ä¿®æ­£
            if "Invalid \\escape" in str(e):
                # ä¸€èˆ¬çš„ãªã‚¨ã‚¹ã‚±ãƒ¼ãƒ—æ–‡å­—ã‚’ä¿®æ­£
                json_str = json_str.replace('\\n', '\\\\n')
                json_str = json_str.replace('\\"', '\\\\"')
                json_str = json_str.replace('\\t', '\\\\t')
                json_str = json_str.replace('\\r', '\\\\r')

                try:
                    return json.loads(json_str)
                except json.JSONDecodeError:
                    # ãã‚Œã§ã‚‚å¤±æ•—ã™ã‚‹å ´åˆã¯ã€ã‚ˆã‚Šç©æ¥µçš„ãªä¿®æ­£
                    import re
                    # ãƒãƒƒã‚¯ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’é©åˆ‡ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
                    json_str = re.sub(r'\\(?!["\\/bfnrt])', r'\\\\', json_str)
                    return json.loads(json_str)
            else:
                raise e

    def _create_fallback_response(self, response_model: BaseModel) -> BaseModel:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä½œæˆ"""
        if response_model == AdditionalQueriesResponse:
            return AdditionalQueriesResponse(keywords=["è¿½åŠ æ¤œç´¢ãŒå¿…è¦"])
        elif response_model == AnalysisResponse:
            return AnalysisResponse(main_facts=["æ¤œç´¢çµæœã®åˆ†æãŒå¿…è¦"])
        elif response_model == SummaryResponse:
            return SummaryResponse(
                key_facts=["è¦ç´„ãŒå¿…è¦"],
                conclusion="æ¤œç´¢çµæœã®è¦ç´„ãŒå¿…è¦ã§ã™"
            )
        else:
            return response_model()

class OllamaModel(LanguageModel):
    """Ollamaãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«"""

    def __init__(self, config: Config):
        self.model_name = config.get('language_model.ollama.model_name', 'llama2')
        self.base_url = config.get('language_model.ollama.base_url', 'http://localhost:11434')

    def generate(self, prompt: str) -> str:
        """Ollama APIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ"""
        try:
            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model_name,
                    "prompt": prompt,
                    "stream": False
                },
                timeout=60  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’60ç§’ã«è¨­å®š
            )
            response.raise_for_status()
            return response.json()["response"]
        except requests.exceptions.Timeout:
            return f"Ollama API ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: ãƒ¢ãƒ‡ãƒ« {self.model_name} ã®å¿œç­”ãŒ60ç§’ã‚’è¶…ãˆã¾ã—ãŸ"
        except requests.exceptions.ConnectionError:
            return f"Ollama API æ¥ç¶šã‚¨ãƒ©ãƒ¼: {self.base_url} ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚OllamaãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„"
        except requests.exceptions.RequestException as e:
            return f"Ollama API ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}"
        except Exception as e:
            return f"Ollama API äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}"

class OpenAIModel(LanguageModel):
    """OpenAI APIãƒ¢ãƒ‡ãƒ«"""

    def __init__(self, config: Config):
        self.api_key = os.getenv("OPENAI_API_KEY")
        self.model = config.get('language_model.openai.model', 'gpt-3.5-turbo')
        self.max_tokens = config.get('language_model.openai.max_tokens', 2000)
        self.temperature = config.get('language_model.openai.temperature', 0.7)

        if not self.api_key:
            raise ValueError("OpenAI API ã‚­ãƒ¼ãŒå¿…è¦ã§ã™")

    def generate(self, prompt: str) -> str:
        """OpenAI APIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ"""
        try:
            import openai
            client = openai.OpenAI(api_key=self.api_key)

            response = client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=self.max_tokens,
                temperature=self.temperature
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"OpenAI API ã‚¨ãƒ©ãƒ¼: {e}"

class GoogleGeminiModel(LanguageModel):
    """Google Gemini APIãƒ¢ãƒ‡ãƒ«"""

    def __init__(self, config: Config):
        self.api_key = os.getenv("GOOGLE_API_KEY")
        self.model = config.get('language_model.gemini.model', 'gemini-2.0-flash')
        self.temperature = config.get('language_model.gemini.temperature', 0.7)

        if not self.api_key:
            raise ValueError("Google API ã‚­ãƒ¼ãŒå¿…è¦ã§ã™")

    def generate(self, prompt: str) -> str:
        """Google Gemini APIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ"""
        try:
            import google.generativeai as genai
            genai.configure(api_key=self.api_key)
            model = genai.GenerativeModel(self.model)
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            return f"Google Gemini API ã‚¨ãƒ©ãƒ¼: {e}"

class DuckDuckGoSearcher:
    """DuckDuckGoæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self, rate_limit: int = 2, max_retries: int = 3):
        self.rate_limit = rate_limit  # ç§’é–“ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°
        self.max_retries = max_retries
        self.last_request_time = 0
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })

    def search(self, query: str, num_results: int = 10) -> List[SearchResult]:
        """DuckDuckGoã§æ¤œç´¢ã‚’å®Ÿè¡Œ"""
        print(f"ğŸ” DuckDuckGoæ¤œç´¢å®Ÿè¡Œ: {query}")

        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’é©ç”¨
        self._apply_rate_limit()

        try:
            # DuckDuckGo Instant Answer APIã‚’ä½¿ç”¨
            url = "https://api.duckduckgo.com/"
            params = {
                'q': query,
                'format': 'json',
                'no_html': '1',
                'skip_disambig': '1'
            }

            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()

            data = response.json()
            results = []

            # Instant Answerã‹ã‚‰çµæœã‚’æŠ½å‡º
            if data.get('Abstract'):
                results.append(SearchResult(
                    title=data.get('AbstractSource', 'DuckDuckGo Instant Answer'),
                    url=data.get('AbstractURL', ''),
                    snippet=data.get('Abstract', ''),
                    search_query=query,
                    reliability_score=0.8,
                    source_type="instant_answer"
                ))

            # Related Topicsã‹ã‚‰çµæœã‚’æŠ½å‡º
            for topic in data.get('RelatedTopics', [])[:num_results-1]:
                if isinstance(topic, dict) and topic.get('Text'):
                    results.append(SearchResult(
                        title=topic.get('FirstURL', '').split('/')[-1] if topic.get('FirstURL') else 'Related Topic',
                        url=topic.get('FirstURL', ''),
                        snippet=topic.get('Text', ''),
                        search_query=query,
                        reliability_score=0.6,
                        source_type="related_topic"
                    ))

            # çµæœãŒå°‘ãªã„å ´åˆã¯ã€HTMLæ¤œç´¢ã‚‚è©¦è¡Œ
            if len(results) < num_results:
                html_results = self._search_html(query, num_results - len(results))
                results.extend(html_results)

            # ãã‚Œã§ã‚‚çµæœãŒå°‘ãªã„å ´åˆã¯ã€ã‚¯ã‚¨ãƒªã‚’ç°¡ç•¥åŒ–ã—ã¦å†è©¦è¡Œ
            if len(results) < 3 and len(query.split()) > 3:
                print(f"âš ï¸  çµæœãŒå°‘ãªã„ãŸã‚ã€ã‚¯ã‚¨ãƒªã‚’ç°¡ç•¥åŒ–ã—ã¦å†è©¦è¡Œ: {query}")
                simplified_query = self._simplify_query(query)
                if simplified_query != query:
                    simplified_results = self._search_simplified(simplified_query, num_results - len(results))
                    results.extend(simplified_results)

            print(f"âœ… DuckDuckGoæ¤œç´¢å®Œäº†: {len(results)}ä»¶ã®çµæœ")
            return results[:num_results]

        except Exception as e:
            print(f"âŒ DuckDuckGoæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def _simplify_query(self, query: str) -> str:
        """ã‚¯ã‚¨ãƒªã‚’ç°¡ç•¥åŒ–"""
        # å¹´å·ã‚„å…·ä½“çš„ãªæ—¥ä»˜ã‚’å‰Šé™¤
        import re
        simplified = re.sub(r'\d{4}å¹´', '', query)
        simplified = re.sub(r'\d{1,2}æœˆ', '', simplified)
        simplified = re.sub(r'\d{1,2}æ—¥', '', simplified)

        # è¤‡æ•°ã®ç©ºç™½ã‚’å˜ä¸€ã®ç©ºç™½ã«
        simplified = re.sub(r'\s+', ' ', simplified)

        # å…ˆé ­ã¨æœ«å°¾ã®ç©ºç™½ã‚’å‰Šé™¤
        simplified = simplified.strip()

        # 3å˜èªä»¥ä¸Šã®å ´åˆã€æœ€åˆã®3å˜èªã®ã¿ã‚’ä½¿ç”¨
        words = simplified.split()
        if len(words) > 3:
            simplified = ' '.join(words[:3])

        return simplified

    def _search_simplified(self, simplified_query: str, num_results: int) -> List[SearchResult]:
        """ç°¡ç•¥åŒ–ã•ã‚ŒãŸã‚¯ã‚¨ãƒªã§æ¤œç´¢"""
        try:
            print(f"ğŸ”„ ç°¡ç•¥åŒ–ã‚¯ã‚¨ãƒªã§æ¤œç´¢: {simplified_query}")
            return self._search_html(simplified_query, num_results)
        except Exception as e:
            print(f"âŒ ç°¡ç•¥åŒ–ã‚¯ã‚¨ãƒªæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def _search_html(self, query: str, num_results: int) -> List[SearchResult]:
        """DuckDuckGoã®HTMLæ¤œç´¢ã‚’å®Ÿè¡Œï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        try:
            url = "https://html.duckduckgo.com/html/"
            params = {
                'q': query
            }

            response = self.session.post(url, data=params, timeout=30)
            response.raise_for_status()

            soup = BeautifulSoup(response.text, 'html.parser')
            results = []

            # æ¤œç´¢çµæœã‚’æŠ½å‡º
            for result in soup.select('.result')[:num_results]:
                title_elem = result.select_one('.result__title')
                snippet_elem = result.select_one('.result__snippet')
                link_elem = result.select_one('.result__url')

                if title_elem and snippet_elem:
                    title = title_elem.get_text(strip=True)
                    snippet = snippet_elem.get_text(strip=True)
                    url = link_elem.get('href') if link_elem else ''

                    # DuckDuckGoã®ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆURLã‚’å‡¦ç†
                    if url.startswith('/l/?uddg='):
                        url = url.replace('/l/?uddg=', '')

                    results.append(SearchResult(
                        title=title,
                        url=url,
                        snippet=snippet,
                        search_query=query,
                        reliability_score=0.5,
                        source_type="html_search"
                    ))

            return results

        except Exception as e:
            print(f"âŒ DuckDuckGo HTMLæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def _apply_rate_limit(self):
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’é©ç”¨"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        min_interval = 1.0 / self.rate_limit

        if time_since_last < min_interval:
            sleep_time = min_interval - time_since_last
            time.sleep(sleep_time)

        self.last_request_time = time.time()

class WebSearcher:
    """Webæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆGoogle Custom Search APIï¼‰"""

    def __init__(self, api_key: str, search_engine_id: str, rate_limit: int = 2, max_retries: int = 5):
        self.api_key = api_key
        self.search_engine_id = search_engine_id
        self.rate_limit = rate_limit
        self.max_retries = max_retries
        self.last_request_time = 0
        self.cache = {}
        self.session = requests.Session()

        print(f"ğŸ”§ WebSearcheråˆæœŸåŒ–:")
        print(f"   APIã‚­ãƒ¼: {'è¨­å®šæ¸ˆã¿' if api_key else 'æœªè¨­å®š'}")
        print(f"   æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ID: {'è¨­å®šæ¸ˆã¿' if search_engine_id else 'æœªè¨­å®š'}")
        print(f"   ãƒ¬ãƒ¼ãƒˆåˆ¶é™: {rate_limit} req/sec, {max_retries}å›ãƒªãƒˆãƒ©ã‚¤")

    def search(self, query: str, num_results: int = 10) -> List[SearchResult]:
        """Google Custom Search APIã§æ¤œç´¢ã‚’å®Ÿè¡Œ"""
        print(f"ğŸ” Googleæ¤œç´¢å®Ÿè¡Œ: {query}")

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒã‚§ãƒƒã‚¯
        cache_key = f"{query}_{num_results}"
        if cache_key in self.cache:
            print(f"ğŸ“‹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰çµæœã‚’å–å¾—: {query}")
            return self.cache[cache_key]

        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’é©ç”¨
        self._apply_rate_limit()

        for attempt in range(self.max_retries):
            try:
                url = "https://www.googleapis.com/customsearch/v1"
                params = {
                    'key': self.api_key,
                    'cx': self.search_engine_id,
                    'q': query,
                    'num': min(num_results, 10),  # Google APIã®æœ€å¤§å€¤ã¯10
                    'dateRestrict': 'm6',  # éå»6ãƒ¶æœˆ
                    'sort': 'date'  # æ—¥ä»˜é †
                }

                response = self.session.get(url, params=params, timeout=30)

                if response.status_code == 429:
                    print(f"âš ï¸  APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸï¼ˆè©¦è¡Œ {attempt + 1}/{self.max_retries}ï¼‰")
                    if attempt < self.max_retries - 1:
                        wait_time = (2 ** attempt) + random.uniform(0, 1)
                        print(f"   {wait_time:.1f}ç§’å¾…æ©Ÿä¸­...")
                        time.sleep(wait_time)
                        continue
                    else:
                        print("âŒ æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸ")
                        return []

                response.raise_for_status()
                data = response.json()

                results = []
                for item in data.get('items', []):
                    # æ—¥ä»˜æƒ…å ±ã‚’æŠ½å‡º
                    date_info = self._extract_date_info(item)

                    # ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
                    reliability_score = self._calculate_reliability_score(item)

                    # ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š
                    source_type = self._determine_source_type(item.get('displayLink', ''))

                    results.append(SearchResult(
                        title=item.get('title', ''),
                        url=item.get('link', ''),
                        snippet=item.get('snippet', ''),
                        search_query=query,
                        date_info=date_info,
                        reliability_score=reliability_score,
                        source_type=source_type
                    ))

                # çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
                self.cache[cache_key] = results

                print(f"âœ… Googleæ¤œç´¢å®Œäº†: {len(results)}ä»¶ã®çµæœ")
                return results

            except requests.exceptions.RequestException as e:
                print(f"âŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ï¼ˆè©¦è¡Œ {attempt + 1}/{self.max_retries}ï¼‰: {e}")
                if attempt < self.max_retries - 1:
                    wait_time = (2 ** attempt) + random.uniform(0, 1)
                    print(f"   {wait_time:.1f}ç§’å¾…æ©Ÿä¸­...")
                    time.sleep(wait_time)
                else:
                    print("âŒ æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸ")
                    return []
            except Exception as e:
                print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
                return []

        return []

    def _extract_date_info(self, item: Dict) -> Optional[str]:
        """æ¤œç´¢çµæœã‹ã‚‰æ—¥ä»˜æƒ…å ±ã‚’æŠ½å‡º"""
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ—¥ä»˜ã‚’æ¢ã™
        metatags = item.get('pagemap', {}).get('metatags', [{}])[0]

        # æ§˜ã€…ãªæ—¥ä»˜ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
        date_fields = [
            'article:published_time',
            'article:modified_time',
            'og:updated_time',
            'lastmod',
            'date',
            'pubdate'
        ]

        for field in date_fields:
            if field in metatags:
                return metatags[field]

        # ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‹ã‚‰æ—¥ä»˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™
        snippet = item.get('snippet', '')
        date_patterns = [
            r'(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',
            r'(\d{4}/\d{1,2}/\d{1,2})',
            r'(\d{4}-\d{1,2}-\d{1,2})',
            r'(\d{1,2}/\d{1,2}/\d{4})'
        ]

        for pattern in date_patterns:
            match = re.search(pattern, snippet)
            if match:
                return match.group(1)

        return None

    def _calculate_reliability_score(self, item: Dict) -> float:
        """æ¤œç´¢çµæœã®ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        score = 0.5  # ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢

        # ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ä¿¡é ¼æ€§
        display_link = item.get('displayLink', '').lower()

        # å…¬å¼ã‚µã‚¤ãƒˆã‚„ä¿¡é ¼ã§ãã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³
        trusted_domains = [
            'aig.co.jp', 'aig.com', 'travel.aig.co.jp',
            'jata-net.or.jp', 'sompo-japan.co.jp',
            'tokyomarine-nichido.co.jp', 'ms-ins.com',
            'sonpo.co.jp', 'aioinissaydowa.co.jp'
        ]

        for domain in trusted_domains:
            if domain in display_link:
                score += 0.3
                break

        # ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚µã‚¤ãƒˆ
        news_domains = [
            'reuters.com', 'bloomberg.com', 'nikkei.com',
            'asahi.com', 'mainichi.jp', 'yomiuri.co.jp'
        ]

        for domain in news_domains:
            if domain in display_link:
                score += 0.2
                break

        # æ”¿åºœãƒ»å…¬çš„æ©Ÿé–¢
        gov_domains = [
            'go.jp', 'meti.go.jp', 'mlit.go.jp',
            'fsa.go.jp', 'jata-net.or.jp'
        ]

        for domain in gov_domains:
            if domain in display_link:
                score += 0.4
                break

        return min(score, 1.0)

    def _determine_source_type(self, display_link: str) -> str:
        """ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š"""
        display_link = display_link.lower()

        if any(domain in display_link for domain in ['aig.co.jp', 'aig.com']):
            return "official"
        elif any(domain in display_link for domain in ['reuters.com', 'bloomberg.com', 'nikkei.com']):
            return "news"
        elif any(domain in display_link for domain in ['go.jp', 'meti.go.jp']):
            return "government"
        elif any(domain in display_link for domain in ['jata-net.or.jp', 'sompo-japan.co.jp']):
            return "industry"
        else:
            return "general"

    def _apply_rate_limit(self):
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’é©ç”¨"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        min_interval = 1.0 / self.rate_limit

        if time_since_last < min_interval:
            sleep_time = min_interval - time_since_last
            time.sleep(sleep_time)

        self.last_request_time = time.time()

class HybridSearcher:
    """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆGoogle + DuckDuckGoï¼‰"""

    def __init__(self, google_api_key: str = None, google_search_engine_id: str = None,
                 preferred_engine: str = "google", rate_limit: int = 2):
        self.google_searcher = None
        self.duckduckgo_searcher = None
        self.preferred_engine = preferred_engine.lower()
        self.rate_limit = rate_limit

        # Googleæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–
        if google_api_key and google_search_engine_id:
            self.google_searcher = WebSearcher(
                api_key=google_api_key,
                search_engine_id=google_search_engine_id,
                rate_limit=rate_limit
            )
            print("âœ… Googleæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
        else:
            print("âš ï¸  Google APIã‚­ãƒ¼ã¾ãŸã¯Search Engine IDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            if not google_api_key:
                print("   - GOOGLE_SEARCH_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            if not google_search_engine_id:
                print("   - GOOGLE_SEARCH_ENGINE_ID ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

        # DuckDuckGoæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–
        self.duckduckgo_searcher = DuckDuckGoSearcher(rate_limit=rate_limit)
        print("âœ… DuckDuckGoæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")

        print(f"ğŸ”§ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
        print(f"   å„ªå…ˆã‚¨ãƒ³ã‚¸ãƒ³: {self.preferred_engine}")
        print(f"   åˆ©ç”¨å¯èƒ½: Google={self.google_searcher is not None}, DuckDuckGo=True")

    def search(self, query: str, num_results: int = 10, force_engine: str = None) -> List[SearchResult]:
        """æ¤œç´¢ã‚’å®Ÿè¡Œï¼ˆæŒ‡å®šã•ã‚ŒãŸã‚¨ãƒ³ã‚¸ãƒ³ã¾ãŸã¯è‡ªå‹•é¸æŠï¼‰"""
        if force_engine:
            engine = force_engine.lower()
        else:
            engine = self.preferred_engine

        if engine == "google":
            if self.google_searcher:
                try:
                    results = self.google_searcher.search(query, num_results)
                    if results:
                        return results
                    else:
                        print("âš ï¸  Googleæ¤œç´¢ã§çµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚DuckDuckGoã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚")
                        return self.duckduckgo_searcher.search(query, num_results)
                except Exception as e:
                    print(f"âŒ Googleæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
                    print("ğŸ”„ DuckDuckGoã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚")
                    return self.duckduckgo_searcher.search(query, num_results)
            else:
                print("âš ï¸  Googleæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚DuckDuckGoã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                return self.duckduckgo_searcher.search(query, num_results)

        elif engine == "duckduckgo":
            return self.duckduckgo_searcher.search(query, num_results)

        elif engine == "auto":
            # è‡ªå‹•é¸æŠï¼šGoogleã‚’å„ªå…ˆã€å¤±æ•—æ™‚ã¯DuckDuckGo
            if self.google_searcher:
                try:
                    results = self.google_searcher.search(query, num_results)
                    if results:
                        return results
                except Exception as e:
                    print(f"âš ï¸  Googleæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")

            print("ğŸ”„ DuckDuckGoã§æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
            return self.duckduckgo_searcher.search(query, num_results)

        else:
            print(f"âŒ ä¸æ˜ãªæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³: {engine}")
            return []

    def get_available_engines(self) -> List[str]:
        """åˆ©ç”¨å¯èƒ½ãªæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        engines = ["duckduckgo"]
        if self.google_searcher:
            engines.append("google")
        return engines

class CitationManager:
    """å¼•ç”¨ç®¡ç†ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, config: Config):
        self.config = config
        self.citations: List[Citation] = []
        self.auto_extract = config.get('citations.auto_extract', True)
        self.relevance_threshold = config.get('citations.relevance_threshold', 0.5)
        self.reliability_threshold = config.get('citations.reliability_threshold', 0.3)

    def create_citations(self, search_results: List[SearchResult]) -> List[Citation]:
        """æ¤œç´¢çµæœã‹ã‚‰å¼•ç”¨ã‚’ä½œæˆ"""
        citations = []
        for result in search_results:
            # ä¿¡é ¼æ€§ã¨é–¢é€£åº¦ã‚’ãƒã‚§ãƒƒã‚¯
            if (result.reliability_score >= self.reliability_threshold and
                result.reliability_score >= self.relevance_threshold):

                citation = Citation(
                    source_title=result.title,
                    source_url=result.url,
                    content=result.snippet,
                    search_query=result.search_query,
                    relevance_score=result.reliability_score,
                    date_info=result.date_info
                )
                citations.append(citation)

        return citations

    def add_citation(self, source: SearchResult, content: str, relevance_score: float = 1.0) -> int:
        """å¼•ç”¨ã‚’è¿½åŠ """
        citation = Citation(
            source_title=source.title,
            source_url=source.url,
            content=content,
            search_query=source.search_query,
            relevance_score=relevance_score,
            date_info=source.date_info
        )
        self.citations.append(citation)
        return len(self.citations)

    def get_citation_text(self, citation_index: int) -> str:
        """å¼•ç”¨ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—"""
        if 0 <= citation_index < len(self.citations):
            citation = self.citations[citation_index]
            return f"[{citation_index + 1}] {citation.source_title}: {citation.content}"
        return ""

    def get_all_citations(self) -> List[Citation]:
        """å…¨ã¦ã®å¼•ç”¨ã‚’å–å¾—"""
        return self.citations

class AdditionalQueriesResponse(BaseModel):
    """è¿½åŠ æ¤œç´¢ã‚¯ã‚¨ãƒªã®æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    additional_queries: List[str] = Field(
        description="è¿½åŠ ã§æ¤œç´¢ã™ã¹ãã‚¯ã‚¨ãƒªã®ãƒªã‚¹ãƒˆ",
        min_items=1,
        max_items=5
    )

    @validator('additional_queries')
    def validate_keywords(cls, v):
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ¤œè¨¼"""
        if not v:
            raise ValueError('ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã¯ç©ºã«ã§ãã¾ã›ã‚“')
        return v

class AnalysisResponse(BaseModel):
    """åˆ†æçµæœã®æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    analysis_text: str = Field(
        description="æ§‹é€ åŒ–ã•ã‚ŒãŸåˆ†æçµæœã®ãƒ†ã‚­ã‚¹ãƒˆ",
        min_length=10,
        default=""
    )

    # å¤ã„å½¢å¼ã¨ã®äº’æ›æ€§ã®ãŸã‚
    main_facts: List[str] = Field(default_factory=list)
    data_statistics: List[str] = Field(default_factory=list)
    different_perspectives: List[str] = Field(default_factory=list)
    date_analysis: List[str] = Field(default_factory=list)
    unknown_points: List[str] = Field(default_factory=list)

    def to_text(self) -> str:
        """æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«å¤‰æ›"""
        if self.analysis_text:
            return self.analysis_text

        # å¤ã„å½¢å¼ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ
        text_parts = []

        if self.main_facts:
            text_parts.append("## ä¸»è¦ãªäº‹å®Ÿ")
            for i, fact in enumerate(self.main_facts, 1):
                text_parts.append(f"{i}. {fact}")

        if self.data_statistics:
            text_parts.append("\n## å…·ä½“çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ")
            for i, stat in enumerate(self.data_statistics, 1):
                text_parts.append(f"{i}. {stat}")

        if self.different_perspectives:
            text_parts.append("\n## ç•°ãªã‚‹è¦–ç‚¹ãƒ»æ„è¦‹")
            for i, perspective in enumerate(self.different_perspectives, 1):
                text_parts.append(f"{i}. {perspective}")

        if self.date_analysis:
            text_parts.append("\n## æ—¥ä»˜åˆ†æ")
            for i, date_info in enumerate(self.date_analysis, 1):
                text_parts.append(f"{i}. {date_info}")

        if self.unknown_points:
            text_parts.append("\n## ä¸æ˜ãªç‚¹ãƒ»è¿½åŠ èª¿æŸ»ãŒå¿…è¦ãªé …ç›®")
            for i, point in enumerate(self.unknown_points, 1):
                text_parts.append(f"{i}. {point}")

        return "\n".join(text_parts) if text_parts else "åˆ†æçµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"

class SummaryResponse(BaseModel):
    """è¦ç´„ã®æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    summary_text: str = Field(
        description="è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆ",
        min_length=10,
        default=""
    )

    # å¤ã„å½¢å¼ã¨ã®äº’æ›æ€§ã®ãŸã‚
    key_facts: List[str] = Field(default_factory=list)
    conclusion: str = Field(default="")
    date_summary: str = Field(default="")

    def to_text(self) -> str:
        """æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«å¤‰æ›"""
        if self.summary_text:
            return self.summary_text

        # å¤ã„å½¢å¼ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ
        text_parts = []

        if self.key_facts:
            text_parts.append("## é‡è¦ãªäº‹å®Ÿ")
            for i, fact in enumerate(self.key_facts, 1):
                text_parts.append(f"{i}. {fact}")

        if self.conclusion:
            text_parts.append(f"\n## çµè«–\n{self.conclusion}")

        if self.date_summary:
            text_parts.append(f"\n## æ—¥ä»˜æƒ…å ±\n{self.date_summary}")

        return "\n".join(text_parts) if text_parts else "è¦ç´„ãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"

class FinalReportResponse(BaseModel):
    """æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã®æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    report_text: str = Field(
        description="æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã®å†…å®¹",
        min_length=10
    )

    def to_text(self) -> str:
        """æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«å¤‰æ›"""
        return self.report_text

class DeepResearch:
    """Deep Researchã®ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹ï¼ˆæ”¹å–„ç‰ˆï¼‰"""

    def __init__(self, model_type: str = "ollama", search_engine: str = "auto"):
        """
        DeepResearchã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–

        Args:
            model_type: ä½¿ç”¨ã™ã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚¿ã‚¤ãƒ— ("ollama", "openai", "gemini")
            search_engine: ä½¿ç”¨ã™ã‚‹æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ ("google", "duckduckgo", "auto")
        """
        self.config = Config()
        self.model_type = model_type
        self.search_engine = search_engine.lower()
        self.today_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰åå¾©å›æ•°ã‚’èª­ã¿è¾¼ã¿
        self.max_iterations = self.config.get('iteration.max_iterations', 5)

        # è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
        self.model = self._create_model(self.model_type)
        self.review_model = self._create_model(self.model_type)  # ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã®åˆ¥ãƒ¢ãƒ‡ãƒ«

        # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–
        google_api_key = self.config.get('search.google.api_key')
        google_search_engine_id = self.config.get('search.google.search_engine_id')
        rate_limit = self.config.get('search.rate_limit.requests_per_second', 2)

        # æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®è¨­å®šã‚’èª¿æ•´
        if self.search_engine == "auto":
            preferred_engine = "google"
        elif self.search_engine == "duckduckgo":
            preferred_engine = "duckduckgo"
        else:
            preferred_engine = "google"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

        self.searcher = HybridSearcher(
            google_api_key=google_api_key,
            google_search_engine_id=google_search_engine_id,
            preferred_engine=preferred_engine,
            rate_limit=rate_limit
        )

        self.citation_manager = CitationManager(self.config)
        self.all_search_results: List[SearchResult] = []

        print(f"ğŸ”§ DeepResearchåˆæœŸåŒ–å®Œäº†")
        print(f"   ãƒ¢ãƒ‡ãƒ«: {model_type}")
        print(f"   æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³: {self.search_engine}")
        print(f"   æœ€å¤§åå¾©å›æ•°: {self.max_iterations}")
        print(f"   åˆ©ç”¨å¯èƒ½ãªæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³: {', '.join(self.searcher.get_available_engines())}")

    def research(self, query: str, max_iterations: int = None, force_engine: str = None) -> ResearchResult:
        """
        ç ”ç©¶ã‚’å®Ÿè¡Œ

        Args:
            query: ç ”ç©¶ã‚¯ã‚¨ãƒª
            max_iterations: æœ€å¤§åå¾©å›æ•°ï¼ˆNoneã®å ´åˆã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å€¤ã‚’ä½¿ç”¨ï¼‰
            force_engine: å¼·åˆ¶çš„ã«ä½¿ç”¨ã™ã‚‹æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ ("google", "duckduckgo")

        Returns:
            ResearchResult: ç ”ç©¶çµæœ
        """
        # åå¾©å›æ•°ã®æ±ºå®š
        if max_iterations is None:
            max_iterations = self.max_iterations

        print(f"ğŸ”¬ Deep Researché–‹å§‹: {query}")
        print(f"   æœ€å¤§åå¾©å›æ•°: {max_iterations}")

        # æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®æ±ºå®š
        if force_engine:
            search_engine = force_engine
        elif self.search_engine == "auto":
            search_engine = None  # è‡ªå‹•é¸æŠ
        else:
            search_engine = self.search_engine

        print(f"   ä½¿ç”¨æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³: {search_engine or 'è‡ªå‹•é¸æŠ'}")
        print("=" * 60)

        # åˆæœŸæ¤œç´¢
        initial_results = self.searcher.search(query, num_results=10, force_engine=search_engine)
        if not initial_results:
            print("âŒ åˆæœŸæ¤œç´¢ã§çµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            return ResearchResult(
                query=query,
                search_results=[],
                analysis="æ¤œç´¢çµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚",
                summary="æ¤œç´¢çµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚",
                final_report="æ¤œç´¢çµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚",
                additional_queries=[],
                citations=[]
            )

        self.all_search_results = initial_results.copy()

        # åˆ†æã¨è¦ç´„ã‚’ç”Ÿæˆ
        analysis = self._analyze_results(query, initial_results)
        summary = self._create_summary(query, analysis)

        additional_queries = []

        # åå¾©æ¤œç´¢
        for iteration in range(max_iterations - 1):
            print(f"\nğŸ”„ åå¾©æ¤œç´¢ {iteration + 1}/{max_iterations - 1}")

            # è¿½åŠ æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ
            new_queries = self._generate_additional_queries(query, analysis, summary)

            # æ–°ã—ã„ã‚¯ã‚¨ãƒªãŒãªã„å ´åˆã¯çµ‚äº†
            if not new_queries:
                print("   æ–°ã—ã„æ¤œç´¢ã‚¯ã‚¨ãƒªãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                break

            # é‡è¤‡ã‚’é™¤å»
            new_queries = [q for q in new_queries if q not in additional_queries]
            additional_queries.extend(new_queries)

            print(f"   è¿½åŠ æ¤œç´¢ã‚¯ã‚¨ãƒª: {new_queries}")

            # è¿½åŠ æ¤œç´¢ã‚’å®Ÿè¡Œ
            new_results = []
            for additional_query in new_queries[:3]:  # æœ€å¤§3ã¤ã¾ã§
                results = self.searcher.search(additional_query, num_results=5, force_engine=search_engine)
                new_results.extend(results)

            if not new_results:
                print("   è¿½åŠ æ¤œç´¢ã§çµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                break

            # é‡è¤‡ã‚’é™¤å»ã—ã¦çµæœã‚’è¿½åŠ 
            existing_urls = {result.url for result in self.all_search_results}
            unique_new_results = [result for result in new_results if result.url not in existing_urls]

            if not unique_new_results:
                print("   æ–°ã—ã„çµæœãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                break

            self.all_search_results.extend(unique_new_results)
            print(f"   {len(unique_new_results)}ä»¶ã®æ–°ã—ã„çµæœã‚’è¿½åŠ ")

            # åˆ†æã‚’æ›´æ–°
            analysis = self._analyze_all_results(query, self.all_search_results)
            summary = self._create_summary(query, analysis)

        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
        final_report = self._create_final_report(query, analysis, summary)

        # å¼•ç”¨ã‚’æ•´ç†
        citations = self.citation_manager.create_citations(self.all_search_results)

        # çµæœã‚’æ•´ç†
        result = ResearchResult(
            query=query,
            search_results=self.all_search_results,
            analysis=analysis,
            summary=summary,
            final_report=final_report,
            additional_queries=additional_queries,
            citations=citations
        )

        # å¼•ç”¨ã‚’æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã«çµ±åˆ
        self._organize_citations(analysis, final_report)

        print(f"\nâœ… Deep Researchå®Œäº†")
        print(f"   ç·æ¤œç´¢çµæœæ•°: {len(self.all_search_results)}")
        print(f"   è¿½åŠ æ¤œç´¢ã‚¯ã‚¨ãƒªæ•°: {len(additional_queries)}")
        print(f"   å¼•ç”¨æ•°: {len(citations)}")

        return result

    def _analyze_results(self, query: str, results: List[SearchResult]) -> str:
        """æ¤œç´¢çµæœã‚’åˆ†æ"""
        print(f"ğŸ“Š æ¤œç´¢çµæœã‚’åˆ†æä¸­...")

        # æ¤œç´¢çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«å¤‰æ›
        results_text = ""
        for i, result in enumerate(results, 1):
            date_info = f"ï¼ˆ{result.date_info}ï¼‰" if result.date_info else ""
            reliability_info = f"ä¿¡é ¼æ€§: {result.reliability_score:.2f}ï¼ˆ{result.source_type}ï¼‰"
            results_text += f"""
#### {i}. [{result.title}]({result.url}){date_info}
- **å†…å®¹**: {result.snippet}
- **{reliability_info}**

"""

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        prompt_template = self.config.get('prompts.analysis', """
ä»Šæ—¥ã®æ—¥ä»˜æƒ…å ±: {today_info}

ä»¥ä¸‹ã®æ¤œç´¢çµæœã®ã¿ã‚’åŸºã«ã€'{query}'ã«ã¤ã„ã¦æ§‹é€ åŒ–ã•ã‚ŒãŸè©³ç´°åˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚æ¤œç´¢çµæœã«å«ã¾ã‚Œã¦ã„ãªã„æƒ…å ±ã¯æ¨æ¸¬ã›ãšã€äº‹å®Ÿã®ã¿ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚

æ¤œç´¢çµæœ:
{results_text}

## è©³ç´°åˆ†æã®æŒ‡ç¤º

ä»¥ä¸‹ã®ã‚«ãƒ†ã‚´ãƒªã«åˆ†ã‘ã¦ã€æ¤œç´¢çµæœã‚’æ·±ãåˆ†æã—ã¦ãã ã•ã„ï¼š

### 1. ä¸»è¦ãªäº‹å®Ÿã¨ç™ºè¦‹ï¼ˆé‡è¦åº¦é †ï¼‰
- æ¤œç´¢çµæœã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹æœ€ã‚‚é‡è¦ãªäº‹å®Ÿã‚’10-15å€‹æŠ½å‡º
- å„äº‹å®Ÿã«å…·ä½“çš„ãªãƒ‡ãƒ¼ã‚¿ã€æ•°å€¤ã€çµ±è¨ˆã‚’æ·»ãˆã‚‹
- æ™‚ç³»åˆ—ã§ã®å¤‰åŒ–ã‚„ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’æ˜è¨˜
- ä¿¡é ¼æ€§ã®é«˜ã„æƒ…å ±æºã‹ã‚‰ã®æƒ…å ±ã‚’å„ªå…ˆ

### 2. æŠ€è¡“ãƒ»æ‰‹æ³•ã®è©³ç´°åˆ†æ
- å…·ä½“çš„ãªæ‰‹æ³•ã‚„æŠ€è¡“ã®è©³ç´°èª¬æ˜
- å®Ÿè£…æ–¹æ³•ã‚„æ‰‹é †ã®å…·ä½“çš„ãªæ‰‹é †
- åŠ¹æœæ¸¬å®šã‚„æ¤œè¨¼æ–¹æ³•ã®è©³ç´°
- æˆåŠŸäº‹ä¾‹ã‚„å¤±æ•—äº‹ä¾‹ã®åˆ†æ

### 3. å¸‚å ´ãƒ»æ¥­ç•Œã®æ·±å±¤åˆ†æ
- å¸‚å ´è¦æ¨¡ã€æˆé•·ç‡ã€äºˆæ¸¬ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿
- ç«¶åˆçŠ¶æ³ã¨å·®åˆ¥åŒ–è¦å› ã®åˆ†æ
- æ¥­ç•Œã®èª²é¡Œã¨æ©Ÿä¼šã®è©³ç´°
- è¦åˆ¶ã‚„æ”¿ç­–ã®å½±éŸ¿

### 4. ç§‘å­¦çš„æ ¹æ‹ ã¨ç ”ç©¶ãƒ‡ãƒ¼ã‚¿
- ç ”ç©¶è«–æ–‡ã‚„å®Ÿé¨“çµæœã®è©³ç´°
- çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚„æ•°å€¤ã®è©³ç´°åˆ†æ
- ä¿¡é ¼æ€§ã¨å¦¥å½“æ€§ã®è©•ä¾¡
- ç ”ç©¶ã®é™ç•Œã‚„åˆ¶ç´„äº‹é …

### 5. å®Ÿè·µçš„å¿œç”¨ã¨åŠ¹æœ
- å…·ä½“çš„ãªå®Ÿè·µæ–¹æ³•ã®è©³ç´°
- åŠ¹æœæ¸¬å®šã®æŒ‡æ¨™ã¨çµæœ
- å€‹äººå·®ã‚„æ¡ä»¶ã«ã‚ˆã‚‹åŠ¹æœã®é•ã„
- é•·æœŸçš„ãªåŠ¹æœã¨æŒç¶šæ€§

### 6. èª²é¡Œã¨åˆ¶é™äº‹é …
- ç¾åœ¨ã®èª²é¡Œã‚„å•é¡Œç‚¹ã®è©³ç´°
- æŠ€è¡“çš„ãƒ»å®Ÿç”¨çš„ãªåˆ¶é™
- æƒ…å ±ã®åã‚Šã‚„ä¸è¶³
- æ”¹å–„ãŒå¿…è¦ãªé ˜åŸŸ

### 7. å°†æ¥å±•æœ›ã¨å¯èƒ½æ€§
- æŠ€è¡“ç™ºå±•ã®æ–¹å‘æ€§
- æ–°ãŸãªå¿œç”¨åˆ†é‡ã®å¯èƒ½æ€§
- ç ”ç©¶ãƒ»é–‹ç™ºã®æ–¹å‘æ€§
- å¸‚å ´ã®å°†æ¥äºˆæ¸¬

## é‡è¦ãªæ³¨æ„äº‹é …

1. **äº‹å®Ÿãƒ™ãƒ¼ã‚¹**: æ¤œç´¢çµæœã«å«ã¾ã‚Œã¦ã„ã‚‹æƒ…å ±ã®ã¿ã‚’ä½¿ç”¨
2. **å…·ä½“çš„ãªãƒ‡ãƒ¼ã‚¿**: æ•°å€¤ã€çµ±è¨ˆã€äº‹ä¾‹ã‚’ç©æ¥µçš„ã«æ´»ç”¨
3. **æ™‚ç³»åˆ—ã®ç†è§£**: éå»ãƒ»ç¾åœ¨ãƒ»å°†æ¥ã‚’æ˜ç¢ºã«åŒºåˆ¥
4. **ä¿¡é ¼æ€§ã®è©•ä¾¡**: æƒ…å ±æºã®ä¿¡é ¼æ€§ã«ã¤ã„ã¦è©³ç´°ã«è¨€åŠ
5. **å®¢è¦³æ€§**: æ¨æ¸¬ã‚„ä¸»è¦³ã‚’é¿ã‘ã€äº‹å®Ÿã®ã¿ã‚’è¨˜è¼‰
6. **æ·±ã„æ´å¯Ÿ**: è¡¨é¢çš„ãªæƒ…å ±ã ã‘ã§ãªãã€èƒŒæ™¯ã‚„æ–‡è„ˆã‚‚å«ã‚ã‚‹
7. **å®Ÿç”¨æ€§**: èª­è€…ãŒå®Ÿéš›ã«æ´»ç”¨ã§ãã‚‹æƒ…å ±ã‚’æä¾›

ä¸Šè¨˜ã®æŒ‡ç¤ºã«å¾“ã£ã¦ã€æ§‹é€ åŒ–ã•ã‚ŒãŸè©³ç´°åˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
""")

        prompt = prompt_template.format(
            query=query,
            results_text=results_text,
            today_info=self.today_date
        )

        try:
            # æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ
            response = self.model.generate_structured(prompt, AnalysisResponse)
            print(f"âœ… æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§åˆ†æã‚’ç”Ÿæˆ")
            return response.to_text()
        except Exception as e:
            print(f"âš ï¸  æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ç”Ÿæˆã«å¤±æ•—: {e}")
            print("   ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®æ–¹æ³•ã§åˆ†æã‚’ç”Ÿæˆ")
            return self.model.generate(prompt)

    def _analyze_all_results(self, query: str, all_results: List[SearchResult]) -> str:
        """å…¨ã¦ã®æ¤œç´¢çµæœã‚’åˆ†æ"""
        print(f"ğŸ“Š å…¨æ¤œç´¢çµæœã‚’åˆ†æä¸­...")

        # æ¤œç´¢çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«å¤‰æ›
        results_text = ""
        for i, result in enumerate(all_results, 1):
            date_info = f"ï¼ˆ{result.date_info}ï¼‰" if result.date_info else ""
            reliability_info = f"ä¿¡é ¼æ€§: {result.reliability_score:.2f}ï¼ˆ{result.source_type}ï¼‰"
            results_text += f"""
#### {i}. [{result.title}]({result.url}){date_info}
- **å†…å®¹**: {result.snippet}
- **{reliability_info}**

"""

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        prompt_template = self.config.get('prompts.analysis_all', """
ä»Šæ—¥ã®æ—¥ä»˜æƒ…å ±: {today_info}

ä»¥ä¸‹ã®å…¨ã¦ã®æ¤œç´¢çµæœã®ã¿ã‚’åŸºã«ã€'{query}'ã«ã¤ã„ã¦åŒ…æ‹¬çš„ãªèª¿æŸ»çµæœã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æ¤œç´¢çµæœã«å«ã¾ã‚Œã¦ã„ãªã„æƒ…å ±ã¯æ¨æ¸¬ã›ãšã€äº‹å®Ÿã®ã¿ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚

æ¤œç´¢çµæœ:
{results_text}

åˆ†æã§ã¯ä»¥ä¸‹ã®ç‚¹ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
- æ¤œç´¢çµæœã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹ä¸»è¦ãªäº‹å®Ÿï¼ˆé‡è¦åº¦é †ï¼‰
- æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹å…·ä½“çš„ãªãƒ‡ãƒ¼ã‚¿ã‚„çµ±è¨ˆ
- æ¤œç´¢çµæœã‹ã‚‰èª­ã¿å–ã‚Œã‚‹ç•°ãªã‚‹è¦–ç‚¹ã‚„æ„è¦‹ã®æ¯”è¼ƒ
- å„æƒ…å ±ã®æ—¥ä»˜ï¼ˆæ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹å ´åˆï¼‰ã¨ä»Šæ—¥ã¨ã®é–¢ä¿‚
- å°†æ¥ã®äºˆå®šã‚„éå»ã®æƒ…å ±ã®åŒºåˆ¥
- ä¿¡é ¼æ€§ã®é«˜ã„æƒ…å ±æºã‹ã‚‰ã®æƒ…å ±
- æ¤œç´¢çµæœã‹ã‚‰ã¯ä¸æ˜ãªç‚¹ã‚„èª²é¡Œ

é‡è¦ï¼šæ¤œç´¢çµæœã«å«ã¾ã‚Œã¦ã„ãªã„æƒ…å ±ã¯è¨˜è¼‰ã›ãšã€äº‹å®Ÿã®ã¿ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚
åˆ†æçµæœã‚’æ—¥æœ¬èªã§è©³ã—ãè¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
""")

        prompt = prompt_template.format(
            query=query,
            results_text=results_text,
            today_info=self.today_date
        )

        return self.model.generate(prompt)

    def _create_summary(self, query: str, analysis: str) -> str:
        """åˆ†æçµæœã‹ã‚‰è¦ç´„ã‚’ç”Ÿæˆ"""
        print(f"ğŸ“ è¦ç´„ç”Ÿæˆä¸­...")

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        prompt_template = self.config.get('prompts.summary', """
ä»Šæ—¥ã®æ—¥ä»˜æƒ…å ±: {today_info}

ä»¥ä¸‹ã®åˆ†æçµæœã‚’åŸºã«ã€'{query}'ã«ã¤ã„ã¦è©³ç´°ã§å®Ÿç”¨çš„ãªè¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

åˆ†æçµæœ:
{analysis}

## è¦ç´„ä½œæˆã®æŒ‡ç¤º

ä»¥ä¸‹ã®è¦ç´ ã‚’å«ã‚€è©³ç´°è¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

### 1. ä¸»è¦ãªç™ºè¦‹äº‹é …ï¼ˆ5-7ç‚¹ï¼‰
- æœ€ã‚‚é‡è¦ãªäº‹å®Ÿã‚„ç™ºè¦‹ã‚’å…·ä½“çš„ãªæ•°å€¤ã¨å…±ã«è¨˜è¼‰
- å„ç™ºè¦‹äº‹é …ã®å®Ÿç”¨çš„ãªæ„ç¾©ã‚’æ˜è¨˜
- ä¿¡é ¼æ€§ã®é«˜ã„æƒ…å ±æºã‹ã‚‰ã®æƒ…å ±ã‚’å„ªå…ˆ

### 2. æŠ€è¡“ãƒ»æ‰‹æ³•ã®æ¦‚è¦
- ä¸»è¦ãªæŠ€è¡“ã‚„æ‰‹æ³•ã®æ¦‚è¦
- å®Ÿè£…ã®é›£æ˜“åº¦ã‚„å¿…è¦ãªãƒªã‚½ãƒ¼ã‚¹
- åŠ¹æœæ¸¬å®šã®æ–¹æ³•ã¨çµæœ

### 3. å¸‚å ´ãƒ»æ¥­ç•Œã®ç¾çŠ¶
- å¸‚å ´è¦æ¨¡ã‚„æˆé•·ç‡ã®ä¸»è¦ãƒ‡ãƒ¼ã‚¿
- ç«¶åˆçŠ¶æ³ã®æ¦‚è¦
- æ¥­ç•Œã®ä¸»è¦ãªèª²é¡Œã¨æ©Ÿä¼š

### 4. å®Ÿè·µçš„å¿œç”¨
- å…·ä½“çš„ãªå®Ÿè·µæ–¹æ³•ã®æ¦‚è¦
- åŠ¹æœã®æŒç¶šæ€§ã¨å€‹äººå·®
- å®Ÿè£…ã«ãŠã‘ã‚‹æ³¨æ„ç‚¹

### 5. å°†æ¥å±•æœ›
- æŠ€è¡“ç™ºå±•ã®æ–¹å‘æ€§
- æ–°ãŸãªå¿œç”¨åˆ†é‡ã®å¯èƒ½æ€§
- å¸‚å ´ã®å°†æ¥äºˆæ¸¬

### 6. å®Ÿç”¨çš„ãªç¤ºå”†
- èª­è€…ãŒå®Ÿéš›ã«æ´»ç”¨ã§ãã‚‹å…·ä½“çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹
- æŠ•è³‡ã‚„å°å…¥ã‚’æ¤œè¨ã™ã‚‹éš›ã®åˆ¤æ–­ææ–™
- ãƒªã‚¹ã‚¯ã¨æ©Ÿä¼šã®ãƒãƒ©ãƒ³ã‚¹

## é‡è¦ãªæ³¨æ„äº‹é …

1. **å…·ä½“çš„ãªãƒ‡ãƒ¼ã‚¿**: æ•°å€¤ã€çµ±è¨ˆã€äº‹ä¾‹ã‚’ç©æ¥µçš„ã«æ´»ç”¨
2. **å®Ÿç”¨æ€§**: èª­è€…ãŒå®Ÿéš›ã«æ´»ç”¨ã§ãã‚‹æƒ…å ±ã‚’æä¾›
3. **å®¢è¦³æ€§**: äº‹å®Ÿã«åŸºã¥ã„ãŸå®¢è¦³çš„ãªè¨˜è¿°
4. **èª­ã¿ã‚„ã™ã•**: å°‚é–€çš„ã§ã‚ã‚ŠãªãŒã‚‰ç†è§£ã—ã‚„ã™ã„æ–‡ç« 
5. **æ§‹é€ åŒ–**: è¦‹å‡ºã—ã‚„ç®‡æ¡æ›¸ãã‚’åŠ¹æœçš„ã«ä½¿ç”¨
6. **æ·±ã„æ´å¯Ÿ**: è¡¨é¢çš„ãªæƒ…å ±ã ã‘ã§ãªãã€èƒŒæ™¯ã‚„æ–‡è„ˆã‚‚å«ã‚ã‚‹

ä¸Šè¨˜ã®æŒ‡ç¤ºã«å¾“ã£ã¦ã€è©³ç´°ã§å®Ÿç”¨çš„ãªè¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
""")

        prompt = prompt_template.format(
            query=query,
            analysis=analysis,
            today_info=self.today_date
        )

        try:
            # æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ
            response = self.model.generate_structured(prompt, SummaryResponse)
            print(f"âœ… æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§è¦ç´„ã‚’ç”Ÿæˆ")
            return response.to_text()
        except Exception as e:
            print(f"âš ï¸  æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ç”Ÿæˆã«å¤±æ•—: {e}")
            print("   ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®æ–¹æ³•ã§è¦ç´„ã‚’ç”Ÿæˆ")
            return self.model.generate(prompt)

    def _generate_additional_queries(self, original_query: str, analysis: str, summary: str) -> List[str]:
        """è¿½åŠ æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ"""
        print(f"ğŸ” è¿½åŠ æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆä¸­...")

        # ã‚ˆã‚ŠåŠ¹æœçš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        prompt_template = self.config.get('prompts.additional_queries', """
ä»Šæ—¥ã®æ—¥ä»˜æƒ…å ±: {today_info}

ä»¥ä¸‹ã®ç ”ç©¶çµæœã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ã€è¿½åŠ ã§èª¿ã¹ã‚‹ã¹ãã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚„æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

å…ƒã®ã‚¯ã‚¨ãƒª: {original_query}

åˆ†æçµæœ:
{analysis}

è¦ç´„:
{summary}

ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰è¿½åŠ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ææ¡ˆã—ã¦ãã ã•ã„ï¼š
1. åˆ†æã§è¨€åŠã•ã‚Œã¦ã„ã‚‹ãŒè©³ç´°ãŒä¸è¶³ã—ã¦ã„ã‚‹æ¦‚å¿µ
2. é–¢é€£ã™ã‚‹å°‚é–€ç”¨èªã‚„æŠ€è¡“
3. æ¯”è¼ƒå¯¾è±¡ã¨ãªã‚‹ä»–ã®äº‹ä¾‹ã‚„ãƒ‡ãƒ¼ã‚¿
4. æœ€æ–°ã®æƒ…å ±ã‚„çµ±è¨ˆ
5. åå¯¾æ„è¦‹ã‚„ç•°ãªã‚‹è¦–ç‚¹
6. å¤ã„æƒ…å ±ï¼ˆéå»ã®äºˆå®šã‚„ç™ºå£²æ—¥ï¼‰ã«ã¤ã„ã¦æœ€æ–°çŠ¶æ³ã‚’ç¢ºèªã™ã‚‹ã¹ãé …ç›®
7. å°†æ¥ã®äºˆå®šã«ã¤ã„ã¦æœ€æ–°ã®é€²æ—çŠ¶æ³ã‚’ç¢ºèªã™ã‚‹ã¹ãé …ç›®

ç‰¹ã«ã€è¨˜äº‹å†…ã§ç™ºå£²äºˆå®šæ—¥ã‚„ç™ºè¡¨äºˆå®šæ—¥ãŒä»Šæ—¥ã‚ˆã‚Šå‰ã®å ´åˆã¯ã€å®Ÿéš›ã®ç™ºå£²ãƒ»ç™ºè¡¨çŠ¶æ³ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã®æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
ã¾ãŸã€å°†æ¥ã®äºˆå®šã«ã¤ã„ã¦æœ€æ–°ã®é€²æ—ã‚„å¤‰æ›´ãŒãªã„ã‹ç¢ºèªã™ã‚‹ãŸã‚ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚‚ææ¡ˆã—ã¦ãã ã•ã„ã€‚

å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯å…·ä½“çš„ã§æ¤œç´¢ã—ã‚„ã™ã„å½¢ã§ææ¡ˆã—ã¦ãã ã•ã„ã€‚
ä»¥ä¸‹ã®å½¢å¼ã§æœ€å¤§5ã¤ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ææ¡ˆã—ã¦ãã ã•ã„ï¼š

ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1
ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2
ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰3
ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰4
ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰5

ç•ªå·ã‚„è¨˜å·ã¯ä»˜ã‘ãšã«ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã¿ã‚’æ”¹è¡ŒåŒºåˆ‡ã‚Šã§è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚
""")

        prompt = prompt_template.format(
            original_query=original_query,
            analysis=analysis,
            summary=summary,
            today_info=self.today_date
        )

        try:
            # æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ
            response = self.model.generate_structured(prompt, AdditionalQueriesResponse)
            print(f"âœ… æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§è¿½åŠ ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ")

            # ç”Ÿæˆã•ã‚ŒãŸã‚¯ã‚¨ãƒªã‚’æ¤œè¨¼ãƒ»æ”¹å–„
            validated_queries = self._validate_and_improve_queries(response.additional_queries, original_query)
            return validated_queries
        except Exception as e:
            print(f"âš ï¸  æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ç”Ÿæˆã«å¤±æ•—: {e}")
            print("   ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®æ–¹æ³•ã§è¿½åŠ ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ")

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®æ–¹æ³•
            fallback_prompt = prompt + "\n\nä¸Šè¨˜ã®æŒ‡ç¤ºã«å¾“ã£ã¦ã€è¿½åŠ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
            response_text = self.model.generate(fallback_prompt)

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
            lines = response_text.strip().split('\n')
            queries = []
            for line in lines:
                line = line.strip()
                if line and not line.startswith(('1.', '2.', '3.', '4.', '5.', '-', '*', 'â€¢')):
                    queries.append(line)

            # ç”Ÿæˆã•ã‚ŒãŸã‚¯ã‚¨ãƒªã‚’æ¤œè¨¼ãƒ»æ”¹å–„
            validated_queries = self._validate_and_improve_queries(queries[:5], original_query)
            return validated_queries

    def _validate_and_improve_queries(self, queries: List[str], original_query: str) -> List[str]:
        """ç”Ÿæˆã•ã‚ŒãŸã‚¯ã‚¨ãƒªã‚’æ¤œè¨¼ãƒ»æ”¹å–„"""
        improved_queries = []

        for query in queries:
            if not query or len(query.strip()) < 2:
                continue

            # ç„¡åŠ¹ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’é™¤å¤–
            invalid_patterns = [
                'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰', 'è¿½åŠ ', 'ææ¡ˆ', 'ä»¥ä¸‹ã®', 'å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰', 'ç•ªå·ã‚„è¨˜å·',
                'æ¤œç´¢', 'ã‚¯ã‚¨ãƒª', 'ç”Ÿæˆ', 'ä½œæˆ', 'åˆ†æ', 'è¦ç´„'
            ]

            if any(pattern in query.lower() for pattern in invalid_patterns):
                continue

            # ã‚¯ã‚¨ãƒªã®é•·ã•ã‚’èª¿æ•´ï¼ˆçŸ­ã™ãã‚‹å ´åˆã¯å…ƒã®ã‚¯ã‚¨ãƒªã¨çµ„ã¿åˆã‚ã›ï¼‰
            if len(query.split()) < 2:
                # å…ƒã®ã‚¯ã‚¨ãƒªã®ä¸»è¦éƒ¨åˆ†ã¨çµ„ã¿åˆã‚ã›
                original_words = original_query.split()[:2]
                improved_query = f"{' '.join(original_words)} {query}"
            else:
                improved_query = query

            # é‡è¤‡ã‚’é¿ã‘ã‚‹
            if improved_query not in improved_queries:
                improved_queries.append(improved_query)

        # çµæœãŒå°‘ãªã„å ´åˆã¯ã€åŸºæœ¬çš„ãªã‚¯ã‚¨ãƒªã‚’è¿½åŠ 
        if len(improved_queries) < 3:
            basic_queries = [
                f"{original_query} æœ€æ–°æƒ…å ±",
                f"{original_query} ãƒ‹ãƒ¥ãƒ¼ã‚¹",
                f"{original_query} å‹•å‘"
            ]
            for basic_query in basic_queries:
                if basic_query not in improved_queries:
                    improved_queries.append(basic_query)

        return improved_queries[:5]  # æœ€å¤§5ã¤ã¾ã§

    def _create_final_report(self, query: str, analysis: str, summary: str) -> str:
        """æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆï¼ˆæ”¹å–„ç‰ˆï¼‰"""
        # ä»Šæ—¥ã®æ—¥ä»˜æƒ…å ±ã‚’æº–å‚™
        today_info = f"ä»Šæ—¥ã®æ—¥ä»˜: {self.today_date}"

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—ã€ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨
        prompt_template = self.config.get('prompts.final_report', """
ä»Šæ—¥ã®æ—¥ä»˜æƒ…å ±: {today_info}

ä»¥ä¸‹ã®åˆ†æçµæœã¨è¦ç´„ã‚’åŸºã«ã€'{query}'ã«ã¤ã„ã¦å°‚é–€çš„ã§èª­ã¿ã‚„ã™ã„è©³ç´°ç ”ç©¶ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

åˆ†æçµæœ:
{analysis}

è¦ç´„:
{summary}

## ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã®æŒ‡ç¤º

ä»¥ä¸‹ã®æ§‹é€ ã§ã€å­¦è¡“çš„ã§å°‚é–€çš„ãªè©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

### 1. ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ï¼ˆ300-400æ–‡å­—ï¼‰
- æœ€ã‚‚é‡è¦ãªç™ºè¦‹äº‹é …ã‚’5-7ç‚¹ã«ã¾ã¨ã‚ã‚‹
- å…·ä½“çš„ãªæ•°å€¤ã€ãƒ‡ãƒ¼ã‚¿ã€çµ±è¨ˆã‚’å«ã‚ã‚‹
- ä¸»è¦ãªçµè«–ã¨å®Ÿç”¨çš„ãªç¤ºå”†ã‚’ç°¡æ½”ã«è¿°ã¹ã‚‹
- ç ”ç©¶ã®æ„ç¾©ã¨ä¾¡å€¤ã‚’æ˜ç¢ºã«ç¤ºã™

### 2. ç ”ç©¶èƒŒæ™¯ã¨ç›®çš„
- ç ”ç©¶ãƒ†ãƒ¼ãƒã®é‡è¦æ€§ã¨ç¤¾ä¼šçš„èƒŒæ™¯
- æœ¬ç ”ç©¶ã®ç›®çš„ã¨å­¦è¡“çš„ãƒ»å®Ÿç”¨çš„æ„ç¾©
- ç ”ç©¶ã®ç¯„å›²ã€åˆ¶é™ã€å‰ææ¡ä»¶
- å…ˆè¡Œç ”ç©¶ã¨ã®é–¢é€£æ€§

### 3. ä¸»è¦ãªç™ºè¦‹äº‹é …ï¼ˆè©³ç´°ç‰ˆï¼‰
- æ¤œç´¢çµæœã‹ã‚‰å¾—ã‚‰ã‚ŒãŸé‡è¦ãªäº‹å®Ÿã‚’ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«è©³ç´°æ•´ç†
- å„ç™ºè¦‹äº‹é …ã«å…·ä½“çš„ãªãƒ‡ãƒ¼ã‚¿ã€çµ±è¨ˆã€äº‹ä¾‹ã‚’æ·»ãˆã‚‹
- æƒ…å ±æºã®ä¿¡é ¼æ€§ã¨å¦¥å½“æ€§ã®è©³ç´°è©•ä¾¡
- ç™ºè¦‹äº‹é …ã®ç›¸äº’é–¢ä¿‚ã¨å½±éŸ¿

### 4. æŠ€è¡“ãƒ»æ‰‹æ³•ã®è©³ç´°åˆ†æ
- å…·ä½“çš„ãªæ‰‹æ³•ã‚„æŠ€è¡“ã®è©³ç´°èª¬æ˜
- å®Ÿè£…æ–¹æ³•ã‚„æ‰‹é †ã®å…·ä½“çš„ãªæ‰‹é †
- åŠ¹æœæ¸¬å®šã‚„æ¤œè¨¼æ–¹æ³•ã®è©³ç´°
- æˆåŠŸäº‹ä¾‹ã‚„å¤±æ•—äº‹ä¾‹ã®è©³ç´°åˆ†æ
- æŠ€è¡“çš„åˆ¶é™ã¨æ”¹å–„ç‚¹

### 5. å¸‚å ´ãƒ»æ¥­ç•Œã®æ·±å±¤åˆ†æ
- å¸‚å ´è¦æ¨¡ã€æˆé•·ç‡ã€äºˆæ¸¬ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿
- ç«¶åˆçŠ¶æ³ã¨å·®åˆ¥åŒ–è¦å› ã®è©³ç´°åˆ†æ
- æ¥­ç•Œã®èª²é¡Œã¨æ©Ÿä¼šã®è©³ç´°
- è¦åˆ¶ã‚„æ”¿ç­–ã®å½±éŸ¿ã¨å¯¾å¿œ
- åœ°åŸŸåˆ¥ãƒ»ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥ã®åˆ†æ

### 6. ç§‘å­¦çš„æ ¹æ‹ ã¨ç ”ç©¶ãƒ‡ãƒ¼ã‚¿
- ç ”ç©¶è«–æ–‡ã‚„å®Ÿé¨“çµæœã®è©³ç´°åˆ†æ
- çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚„æ•°å€¤ã®è©³ç´°åˆ†æ
- ä¿¡é ¼æ€§ã¨å¦¥å½“æ€§ã®è©³ç´°è©•ä¾¡
- ç ”ç©¶ã®é™ç•Œã‚„åˆ¶ç´„äº‹é …
- å†ç¾æ€§ã¨ä¸€èˆ¬åŒ–å¯èƒ½æ€§

### 7. å®Ÿè·µçš„å¿œç”¨ã¨åŠ¹æœ
- å…·ä½“çš„ãªå®Ÿè·µæ–¹æ³•ã®è©³ç´°
- åŠ¹æœæ¸¬å®šã®æŒ‡æ¨™ã¨çµæœã®è©³ç´°
- å€‹äººå·®ã‚„æ¡ä»¶ã«ã‚ˆã‚‹åŠ¹æœã®é•ã„
- é•·æœŸçš„ãªåŠ¹æœã¨æŒç¶šæ€§
- å®Ÿè£…ã«ãŠã‘ã‚‹æ³¨æ„ç‚¹

### 8. èª²é¡Œã¨åˆ¶é™äº‹é …
- ç¾åœ¨ã®èª²é¡Œã‚„å•é¡Œç‚¹ã®è©³ç´°åˆ†æ
- æŠ€è¡“çš„ãƒ»å®Ÿç”¨çš„ãªåˆ¶é™ã®è©³ç´°
- æƒ…å ±ã®åã‚Šã‚„ä¸è¶³ã®å½±éŸ¿
- æ”¹å–„ãŒå¿…è¦ãªé ˜åŸŸã®ç‰¹å®š
- ãƒªã‚¹ã‚¯è¦å› ã®è©³ç´°è©•ä¾¡

### 9. å°†æ¥å±•æœ›ã¨å¯èƒ½æ€§
- æŠ€è¡“ç™ºå±•ã®æ–¹å‘æ€§ã¨äºˆæ¸¬
- æ–°ãŸãªå¿œç”¨åˆ†é‡ã®å¯èƒ½æ€§
- ç ”ç©¶ãƒ»é–‹ç™ºã®æ–¹å‘æ€§
- å¸‚å ´ã®å°†æ¥äºˆæ¸¬ã¨ã‚·ãƒŠãƒªã‚ª
- æŠ•è³‡æ©Ÿä¼šã¨æˆ¦ç•¥çš„ç¤ºå”†

### 10. çµè«–ã¨æè¨€
- ä¸»è¦ãªçµè«–ã®è©³ç´°ãªã¾ã¨ã‚
- å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³
- æ”¿ç­–ãƒ»åˆ¶åº¦ã¸ã®æè¨€
- ä»Šå¾Œã®ç ”ç©¶æ–¹å‘
- å®Ÿè·µè€…ã¸ã®å…·ä½“çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹

## é‡è¦ãªæ³¨æ„äº‹é …

1. **é‡è¤‡ã‚’é¿ã‘ã‚‹**: å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§åŒã˜å†…å®¹ã‚’ç¹°ã‚Šè¿”ã•ãªã„
2. **æƒ…å ±ã®å„ªå…ˆé †ä½**: æœ€ã‚‚é‡è¦ãªæƒ…å ±ã‹ã‚‰é †ã«è©³ç´°ã«è¨˜è¼‰
3. **å…·ä½“çš„ãªãƒ‡ãƒ¼ã‚¿**: æ•°å€¤ã€çµ±è¨ˆã€äº‹ä¾‹ã‚’ç©æ¥µçš„ã«æ´»ç”¨
4. **å®¢è¦³æ€§**: äº‹å®Ÿã«åŸºã¥ã„ãŸå®¢è¦³çš„ãªè¨˜è¿°
5. **èª­ã¿ã‚„ã™ã•**: å°‚é–€çš„ã§ã‚ã‚ŠãªãŒã‚‰ç†è§£ã—ã‚„ã™ã„æ–‡ç« 
6. **æ§‹é€ åŒ–**: è¦‹å‡ºã—ã€ç®‡æ¡æ›¸ãã€è¡¨ãªã©ã‚’åŠ¹æœçš„ã«ä½¿ç”¨
7. **æ·±ã„æ´å¯Ÿ**: è¡¨é¢çš„ãªæƒ…å ±ã ã‘ã§ãªãã€èƒŒæ™¯ã‚„æ–‡è„ˆã‚‚å«ã‚ã‚‹
8. **å®Ÿç”¨æ€§**: èª­è€…ãŒå®Ÿéš›ã«æ´»ç”¨ã§ãã‚‹å…·ä½“çš„ãªæƒ…å ±ã‚’æä¾›

## æ–‡ä½“ã¨ãƒˆãƒ¼ãƒ³

- å°‚é–€çš„ã§ä¿¡é ¼æ€§ã®é«˜ã„æ–‡ä½“
- ãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸ã¨ã—ã¦é©åˆ‡ãªå½¢å¼
- èª­è€…ãŒå®Ÿç”¨çš„ãªæƒ…å ±ã‚’å¾—ã‚‰ã‚Œã‚‹å†…å®¹
- å­¦è¡“çš„ã§ã‚ã‚ŠãªãŒã‚‰å®Ÿè·µçš„
- å®¢è¦³çš„ã§ã‚ã‚ŠãªãŒã‚‰æ´å¯Ÿã«å¯Œã‚€

ä¸Šè¨˜ã®æŒ‡ç¤ºã«å¾“ã£ã¦ã€é«˜å“è³ªãªè©³ç´°ç ”ç©¶ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
""")

        prompt = prompt_template.format(
            query=query,
            analysis=analysis,
            summary=summary,
            today_info=today_info
        )

        try:
            # æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ
            response = self.model.generate_structured(prompt, FinalReportResponse)
            print(f"âœ… æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ")
            return response.to_text()
        except Exception as e:
            print(f"âš ï¸  æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ç”Ÿæˆã«å¤±æ•—: {e}")
            print("   ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®æ–¹æ³•ã§ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ")

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®æ–¹æ³•
            fallback_prompt = prompt + "\n\nä¸Šè¨˜ã®æŒ‡ç¤ºã«å¾“ã£ã¦ã€å°‚é–€çš„ã§èª­ã¿ã‚„ã™ã„ç ”ç©¶ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
            return self.model.generate(fallback_prompt)

    def _organize_citations(self, analysis: str, final_report: str):
        """å¼•ç”¨ã‚’æ•´ç†ã—ã¦æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã«çµ±åˆ"""
        # ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯æ—¢å­˜ã®å®Ÿè£…ã‚’ãã®ã¾ã¾ä½¿ç”¨
        pass

    def save_to_markdown(self, result: ResearchResult, filename: str = None) -> str:
        """çµæœã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
        if not filename:
            base_filename = f"research_{result.query.replace(' ', '_')}.md"
        else:
            base_filename = filename

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆè¨­å®šã‚’å–å¾—
        duplicate_handling = self.config.get('output.filename_generation.duplicate_handling', 'both')
        timestamp_format = self.config.get('output.filename_generation.timestamp_format', 'YYYYMMDD_HHMMSS')
        version_prefix = self.config.get('output.filename_generation.version_prefix', 'v')

        # outputãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã‚’å–å¾—
        output_dir = self.config.get('output.directory', './output')

        # outputãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
        os.makedirs(output_dir, exist_ok=True)

        # outputãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
        output_path = os.path.join(output_dir, base_filename)

        # ãƒ•ã‚¡ã‚¤ãƒ«åã®é‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ã«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·ã‚’ä»˜ã‘ã‚‹
        filename = self._get_unique_filename(output_path, duplicate_handling, timestamp_format, version_prefix)

        # å¼•ç”¨ãƒªãƒ³ã‚¯ã®è¾æ›¸ã‚’ä½œæˆ
        citation_links = {}
        for i, citation in enumerate(result.citations, 1):
            citation_links[f"[{i}]"] = f"[{i}]({citation.source_url})"

        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã«å¼•ç”¨ãƒªãƒ³ã‚¯ã‚’å·®ã—è¾¼ã¿
        final_report_with_links = result.final_report
        for citation_ref, link in citation_links.items():
            final_report_with_links = final_report_with_links.replace(citation_ref, link)

        # ãƒ¬ãƒãƒ¼ãƒˆã®æ§‹é€ ã‚’æ”¹å–„ï¼ˆã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ã®é‡è¤‡ã‚’è§£æ¶ˆï¼‰
        content = f"""# Deep Research: {result.query}

{final_report_with_links}

## æ¤œç´¢å±¥æ­´
### åˆæœŸæ¤œç´¢
- ã‚¯ã‚¨ãƒª: {result.query}

### è¿½åŠ æ¤œç´¢
"""

        # è¿½åŠ æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è¨˜è¼‰
        for i, query in enumerate(result.additional_queries, 1):
            content += f"- è¿½åŠ ã‚¯ã‚¨ãƒª {i}: {query}\n"

        content += f"""
## æ¤œç´¢çµæœï¼ˆ{len(result.search_results)}ä»¶ï¼‰
"""

        # æ¤œç´¢çµæœã‚’ã‚¯ã‚¨ãƒªåˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        query_groups = {}
        for result_item in result.search_results:
            query = result_item.search_query
            if query not in query_groups:
                query_groups[query] = []
            query_groups[query].append(result_item)

        for query, results in query_groups.items():
            content += f"\n### æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}\n"
            for i, search_result in enumerate(results, 1):
                date_info = f"ï¼ˆ{search_result.date_info}ï¼‰" if search_result.date_info else ""
                reliability_info = f"ä¿¡é ¼æ€§: {search_result.reliability_score:.2f}ï¼ˆ{search_result.source_type}ï¼‰"
                content += f"""
#### {i}. [{search_result.title}]({search_result.url}){date_info}
- **å†…å®¹**: {search_result.snippet}
- **{reliability_info}**

"""

        content += f"""
## å¼•ç”¨æ–‡çŒ®
"""

        # å¼•ç”¨æ–‡çŒ®ã‚’è¨˜è¼‰
        for i, citation in enumerate(result.citations, 1):
            date_info = f"ï¼ˆ{citation.date_info}ï¼‰" if citation.date_info else ""
            content += f"""
### [{i}] [{citation.source_title}]({citation.source_url}){date_info}
- **æ¤œç´¢ã‚¯ã‚¨ãƒª**: {citation.search_query}
- **é–¢é€£åº¦**: {citation.relevance_score:.2f}
- **å†…å®¹**: {citation.content}

"""

        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content)

        print(f"ğŸ“„ çµæœã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")
        return filename

    def _get_unique_filename(self, base_filename: str, duplicate_handling: str = "both",
                           timestamp_format: str = "YYYYMMDD_HHMMSS", version_prefix: str = "v") -> str:
        """é‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ã«ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ"""
        if not os.path.exists(base_filename):
            return base_filename

        # ãƒ•ã‚¡ã‚¤ãƒ«åã¨æ‹¡å¼µå­ã‚’åˆ†é›¢
        name, ext = os.path.splitext(base_filename)

        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å½¢å¼ã‚’è¨­å®š
        if timestamp_format == "YYYY-MM-DD_HH-MM-SS":
            timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        else:  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: YYYYMMDD_HHMMSS
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        if duplicate_handling in ["timestamp", "both"]:
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
            timestamped_filename = f"{name}_{timestamp}{ext}"

            if not os.path.exists(timestamped_filename):
                return timestamped_filename

        if duplicate_handling in ["version", "both"]:
            # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·ã‚’ä»˜ã‘ã¦ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
            version = 1
            while True:
                new_filename = f"{name}_{version_prefix}{version}{ext}"
                if not os.path.exists(new_filename):
                    return new_filename
                version += 1

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ— + ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·
        version = 1
        while True:
            new_filename = f"{name}_{timestamp}_{version_prefix}{version}{ext}"
            if not os.path.exists(new_filename):
                return new_filename
            version += 1

    def _parse_date_info(self, date_str: str) -> Dict[str, any]:
        """æ—¥ä»˜æ–‡å­—åˆ—ã‚’è§£æã—ã¦ç›¸å¯¾çš„ãªæƒ…å ±ã‚’å–å¾—"""
        if not date_str:
            return {"is_valid": False, "relative_info": "æ—¥ä»˜ä¸æ˜"}

        try:
            # æ§˜ã€…ãªæ—¥ä»˜å½¢å¼ã‚’è§£æ
            date_patterns = [
                (r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥', '%Yå¹´%mæœˆ%dæ—¥'),
                (r'(\d{4})-(\d{1,2})-(\d{1,2})', '%Y-%m-%d'),
                (r'(\d{4})/(\d{1,2})/(\d{1,2})', '%Y/%m/%d'),
                (r'(\d{1,2})æœˆ(\d{1,2})æ—¥', '%mæœˆ%dæ—¥'),
                (r'(\d{4})å¹´(\d{1,2})æœˆ', '%Yå¹´%mæœˆ'),
                (r'(\d{4})å¹´', '%Yå¹´'),
            ]

            for pattern, format_str in date_patterns:
                match = re.search(pattern, date_str)
                if match:
                    if format_str == '%Yå¹´%mæœˆ%dæ—¥':
                        year, month, day = match.groups()
                        parsed_date = datetime(int(year), int(month), int(day))
                    elif format_str == '%Y-%m-%d':
                        year, month, day = match.groups()
                        parsed_date = datetime(int(year), int(month), int(day))
                    elif format_str == '%Y/%m/%d':
                        year, month, day = match.groups()
                        parsed_date = datetime(int(year), int(month), int(day))
                    elif format_str == '%mæœˆ%dæ—¥':
                        month, day = match.groups()
                        # ä»Šå¹´ã®æ—¥ä»˜ã¨ã—ã¦æ‰±ã†
                        parsed_date = datetime(self.today_year, int(month), int(day))
                    elif format_str == '%Yå¹´%mæœˆ':
                        year, month = match.groups()
                        parsed_date = datetime(int(year), int(month), 1)
                    elif format_str == '%Yå¹´':
                        year = match.groups()[0]
                        parsed_date = datetime(int(year), 1, 1)

                    # ä»Šæ—¥ã¨ã®æ¯”è¼ƒ
                    today = datetime(self.today_year, self.today_month, self.today_day)
                    days_diff = (today - parsed_date).days

                    if days_diff > 0:
                        if days_diff < 7:
                            relative_info = f"{days_diff}æ—¥å‰"
                        elif days_diff < 30:
                            weeks = days_diff // 7
                            relative_info = f"{weeks}é€±é–“å‰"
                        elif days_diff < 365:
                            months = days_diff // 30
                            relative_info = f"{months}ãƒ¶æœˆå‰"
                        else:
                            years = days_diff // 365
                            relative_info = f"{years}å¹´å‰"
                    elif days_diff < 0:
                        if abs(days_diff) < 7:
                            relative_info = f"{abs(days_diff)}æ—¥å¾Œ"
                        elif abs(days_diff) < 30:
                            weeks = abs(days_diff) // 7
                            relative_info = f"{weeks}é€±é–“å¾Œ"
                        elif abs(days_diff) < 365:
                            months = abs(days_diff) // 30
                            relative_info = f"{months}ãƒ¶æœˆå¾Œ"
                        else:
                            years = abs(days_diff) // 365
                            relative_info = f"{years}å¹´å¾Œ"
                    else:
                        relative_info = "ä»Šæ—¥"

                    return {
                        "is_valid": True,
                        "parsed_date": parsed_date,
                        "relative_info": relative_info,
                        "days_diff": days_diff,
                        "is_future": days_diff < 0,
                        "is_recent": days_diff <= 30  # 30æ—¥ä»¥å†…ã‚’æœ€è¿‘ã¨ã™ã‚‹
                    }

            return {"is_valid": False, "relative_info": "æ—¥ä»˜å½¢å¼ãŒä¸æ˜"}

        except Exception as e:
            return {"is_valid": False, "relative_info": f"æ—¥ä»˜è§£æã‚¨ãƒ©ãƒ¼: {str(e)}"}

    def _sort_results_by_reliability(self, results: List[SearchResult]) -> List[SearchResult]:
        """ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ã«åŸºã¥ã„ã¦æ¤œç´¢çµæœã‚’ä¸¦ã³æ›¿ãˆ"""
        return sorted(results, key=lambda x: x.reliability_score, reverse=True)

    def _filter_results_by_reliability(self, results: List[SearchResult], threshold: float = 0.5) -> List[SearchResult]:
        """ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ãŒé–¾å€¤ä»¥ä¸Šã®æ¤œç´¢çµæœã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        return [result for result in results if result.reliability_score >= threshold]

    def _create_model(self, model_type: str) -> LanguageModel:
        """æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¤ãƒ—ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ"""
        if model_type == "ollama":
            return OllamaModel(self.config)
        elif model_type == "openai":
            return OpenAIModel(self.config)
        elif model_type == "gemini":
            return GoogleGeminiModel(self.config)
        else:
            raise ValueError(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {model_type}")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸ”¬ Deep Research Clone (æ”¹å–„ç‰ˆ)")
    print("=" * 50)

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    config_path = "config.yaml"
    if not os.path.exists(config_path):
        print(f"âš ï¸  è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« {config_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        print("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹ã«ã¯ã€config.example.yaml ã‚’ config.yaml ã«ã‚³ãƒ”ãƒ¼ã—ã¦ãã ã•ã„ã€‚")

    # ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’é¸æŠ
    print("ä½¿ç”¨ã™ã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„:")
    print("1. Ollama (ãƒ­ãƒ¼ã‚«ãƒ«)")
    print("2. OpenAI")
    print("3. Google Gemini")

    choice = input("é¸æŠ (1-3): ").strip()

    model_map = {
        "1": "ollama",
        "2": "openai",
        "3": "gemini"
    }

    model_type = model_map.get(choice, "ollama")

    # æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚’é¸æŠ
    print("\nä½¿ç”¨ã™ã‚‹æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚’é¸æŠã—ã¦ãã ã•ã„:")
    print("1. è‡ªå‹•é¸æŠ (Google + DuckDuckGo)")
    print("2. Google ã®ã¿")
    print("3. DuckDuckGo ã®ã¿")

    search_choice = input("é¸æŠ (1-3): ").strip()

    search_engine_map = {
        "1": "auto",
        "2": "google",
        "3": "duckduckgo"
    }

    search_engine = search_engine_map.get(search_choice, "auto")

    try:
        # Deep Researchã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        researcher = DeepResearch(model_type=model_type, search_engine=search_engine)

        # ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›
        query = input("\nğŸ” ç ”ç©¶ã—ãŸã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚„æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip()

        if not query:
            print("ã‚¯ã‚¨ãƒªãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return

        # ç ”ç©¶ã‚’å®Ÿè¡Œ
        result = researcher.research(query)

        # æ¤œç´¢å¤±æ•—ã®å ´åˆ
        if result is None:
            print("\nâŒ ç ”ç©¶ã‚’å®Œäº†ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            return

        # çµæœã‚’è¡¨ç¤º
        print("\n" + "=" * 50)
        print("ğŸ“‹ ç ”ç©¶çµæœ")
        print("=" * 50)
        print(f"ã‚¯ã‚¨ãƒª: {result.query}")
        print(f"æ¤œç´¢çµæœæ•°: {len(result.search_results)}")
        print(f"è¿½åŠ æ¤œç´¢ã‚¯ã‚¨ãƒªæ•°: {len(result.additional_queries)}")
        print(f"å¼•ç”¨æ–‡çŒ®æ•°: {len(result.citations)}")
        print(f"è¦ç´„: {result.summary}")

        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        filename = researcher.save_to_markdown(result)

        print(f"\nâœ… ç ”ç©¶å®Œäº†ï¼çµæœã¯ {filename} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    main()
