#!/usr/bin/env python3
"""
Ollamaæ¥ç¶šãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import requests
import json
import sys

def test_ollama_connection():
    """Ollamaã‚µãƒ¼ãƒãƒ¼ã¸ã®æ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ”§ Ollamaæ¥ç¶šãƒ†ã‚¹ãƒˆ")
    print("=" * 50)

    # æ¥ç¶šå…ˆURL
    base_url = "http://localhost:11434"

    try:
        # 1. ã‚µãƒ¼ãƒãƒ¼ã®çŠ¶æ…‹ç¢ºèª
        print("1. ã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹ç¢ºèª...")
        response = requests.get(f"{base_url}/api/tags", timeout=5)
        if response.status_code == 200:
            print("âœ… Ollamaã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã¾ã™")
        else:
            print(f"âŒ ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: {response.status_code}")
            return False

    except requests.exceptions.ConnectionError:
        print("âŒ Ollamaã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“")
        print("   å¯¾å‡¦æ³•:")
        print("   1. ollama serve ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        print("   2. ãƒãƒ¼ãƒˆ11434ãŒä½¿ç”¨å¯èƒ½ã‹ç¢ºèªã—ã¦ãã ã•ã„")
        return False
    except requests.exceptions.Timeout:
        print("âŒ æ¥ç¶šãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
        return False
    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return False

    try:
        # 2. åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ç¢ºèª
        print("\n2. åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ç¢ºèª...")
        response = requests.get(f"{base_url}/api/tags")
        models = response.json().get('models', [])

        if models:
            print(f"âœ… {len(models)}å€‹ã®ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½:")
            for model in models:
                print(f"   - {model['name']}")
        else:
            print("âš ï¸  åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
            print("   å¯¾å‡¦æ³•: ollama pull llama3.1:8b ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        return False

    try:
        # 3. ç°¡å˜ãªç”Ÿæˆãƒ†ã‚¹ãƒˆ
        print("\n3. ç”Ÿæˆãƒ†ã‚¹ãƒˆ...")
        test_prompt = "ã“ã‚“ã«ã¡ã¯"

        response = requests.post(
            f"{base_url}/api/generate",
            json={
                "model": "llama3.1:8b",
                "prompt": test_prompt,
                "stream": False
            },
            timeout=30
        )

        if response.status_code == 200:
            result = response.json()
            print("âœ… ç”Ÿæˆãƒ†ã‚¹ãƒˆæˆåŠŸ")
            print(f"   ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {result.get('response', '')[:50]}...")
        else:
            print(f"âŒ ç”Ÿæˆãƒ†ã‚¹ãƒˆå¤±æ•—: {response.status_code}")
            print(f"   ã‚¨ãƒ©ãƒ¼: {response.text}")
            return False

    except requests.exceptions.Timeout:
        print("âŒ ç”Ÿæˆãƒ†ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
        return False
    except Exception as e:
        print(f"âŒ ç”Ÿæˆãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

    print("\nğŸ‰ Ollamaæ¥ç¶šãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
    return True

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸ§ª Ollamaæ¥ç¶šãƒ†ã‚¹ãƒˆ")
    print("=" * 50)

    success = test_ollama_connection()

    if not success:
        print("\nğŸ“‹ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°")
        print("=" * 50)
        print("1. OllamaãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª:")
        print("   which ollama")
        print()
        print("2. Ollamaã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•:")
        print("   ollama serve")
        print()
        print("3. ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰:")
        print("   ollama pull llama3.1:8b")
        print()
        print("4. åˆ¥ã®ãƒãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆ:")
        print("   config.yamlã§base_urlã‚’å¤‰æ›´")
        print()
        print("5. ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«è¨­å®šã‚’ç¢ºèª")
        sys.exit(1)
    else:
        print("\nâœ… å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    main()
