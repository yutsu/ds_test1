#!/usr/bin/env python3
"""
æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from main import DeepResearch, AdditionalQueriesResponse, AnalysisResponse, SummaryResponse
import json

class MockStructuredLanguageModel:
    """ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¢ãƒƒã‚¯æ§‹é€ åŒ–è¨€èªãƒ¢ãƒ‡ãƒ«"""

    def generate(self, prompt: str) -> str:
        """ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™"""
        if "è¿½åŠ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰" in prompt or "keywords" in prompt:
            return '''
{
  "keywords": [
    "å¸‚å ´è¦æ¨¡ çµ±è¨ˆ",
    "AIè¦åˆ¶ æ³•å¾‹",
    "å€«ç†ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³",
    "é›‡ç”¨å½±éŸ¿ èª¿æŸ»",
    "åŒ»ç™‚AI å¿œç”¨"
  ]
}
'''
        elif "åˆ†æ" in prompt or "main_facts" in prompt:
            return '''
{
  "main_facts": [
    "2024å¹´ã«AIæŠ€è¡“ãŒå¤§å¹…ã«é€²æ­©ã—ãŸ",
    "å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãŒå‘ä¸Šã—ãŸ",
    "ä¼æ¥­å°å…¥ãŒåŠ é€Ÿã—ã¦ã„ã‚‹"
  ],
  "data_statistics": [
    "å¸‚å ´è¦æ¨¡ã¯å‰å¹´æ¯”30%å¢—åŠ ",
    "ä¼æ¥­å°å…¥ç‡ã¯60%ã«é”ã—ãŸ"
  ],
  "different_perspectives": [
    "æŠ€è¡“çš„é€²æ­©ã‚’è©•ä¾¡ã™ã‚‹æ„è¦‹",
    "é›‡ç”¨ã¸ã®å½±éŸ¿ã‚’æ‡¸å¿µã™ã‚‹æ„è¦‹"
  ],
  "date_analysis": [
    "2024å¹´ã®æƒ…å ±ã¯æœ€æ–°",
    "2023å¹´ã®ãƒ‡ãƒ¼ã‚¿ã¯éå»ã®æƒ…å ±"
  ],
  "unknown_points": [
    "å…·ä½“çš„ãªè¦åˆ¶å†…å®¹",
    "é•·æœŸçš„ãªå½±éŸ¿ã®è©³ç´°"
  ]
}
'''
        elif "è¦ç´„" in prompt or "key_facts" in prompt:
            return '''
{
  "key_facts": [
    "AIæŠ€è¡“ãŒ2024å¹´ã«å¤§å¹…é€²æ­©",
    "ä¼æ¥­å°å…¥ãŒåŠ é€Ÿ",
    "è¦åˆ¶è­°è«–ãŒæ´»ç™ºåŒ–"
  ],
  "conclusion": "AIæŠ€è¡“ã¯æ€¥é€Ÿã«ç™ºå±•ã—ã¦ã„ã‚‹ãŒã€è¦åˆ¶ã‚„å€«ç†é¢ã§ã®èª²é¡Œã‚‚å­˜åœ¨ã™ã‚‹ã€‚é•·æœŸçš„ãªå½±éŸ¿ã«ã¤ã„ã¦ã¯ç¶™ç¶šçš„ãªèª¿æŸ»ãŒå¿…è¦ã§ã‚ã‚‹ã€‚",
  "date_summary": "2024å¹´ã®æœ€æ–°æƒ…å ±ã‚’ä¸­å¿ƒã«æ§‹æˆ"
}
'''
        else:
            return "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§ã™ã€‚"

    def generate_structured(self, prompt: str, response_model):
        """æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ"""
        response_text = self.generate(prompt)

        # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æŠ½å‡ºã—ã¦ãƒ‘ãƒ¼ã‚¹
        try:
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            json_str = response_text[json_start:json_end]
            json_data = json.loads(json_str)
            return response_model(**json_data)
        except Exception as e:
            print(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if response_model == AdditionalQueriesResponse:
                return AdditionalQueriesResponse(keywords=["ãƒ†ã‚¹ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"])
            elif response_model == AnalysisResponse:
                return AnalysisResponse(main_facts=["ãƒ†ã‚¹ãƒˆåˆ†æ"])
            elif response_model == SummaryResponse:
                return SummaryResponse(
                    key_facts=["ãƒ†ã‚¹ãƒˆè¦ç´„"],
                    conclusion="ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆç”¨ã®çµè«–ã§ã™ã€‚ååˆ†ãªé•·ã•ã‚’æŒã¤çµè«–æ–‡ã§ã™ã€‚"
                )

def test_structured_additional_queries():
    """æ§‹é€ åŒ–è¿½åŠ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª æ§‹é€ åŒ–è¿½åŠ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    try:
        # DeepResearchã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        researcher = DeepResearch("ollama")

        # ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã«ç½®ãæ›ãˆ
        researcher.review_model = MockStructuredLanguageModel()

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        original_query = "äººå·¥çŸ¥èƒ½ã®æœ€æ–°å‹•å‘"
        analysis = "2024å¹´ã«AIæŠ€è¡“ãŒå¤§å¹…ã«é€²æ­©ã—ãŸã€‚å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãŒå‘ä¸Šã—ã€ä¼æ¥­å°å…¥ãŒåŠ é€Ÿã—ã¦ã„ã‚‹ã€‚"
        summary = "AIæŠ€è¡“ã¯æ€¥é€Ÿã«ç™ºå±•ã—ã¦ã„ã‚‹ãŒã€è¦åˆ¶ã‚„å€«ç†é¢ã§ã®èª²é¡Œã‚‚å­˜åœ¨ã™ã‚‹ã€‚"

        print(f"å…ƒã®ã‚¯ã‚¨ãƒª: {original_query}")
        print(f"åˆ†æçµæœ: {analysis}")
        print(f"è¦ç´„: {summary}")
        print()

        # æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§è¿½åŠ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
        additional_queries = researcher._generate_additional_queries(
            original_query, analysis, summary
        )

        print("ç”Ÿæˆã•ã‚ŒãŸè¿½åŠ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:")
        for i, query in enumerate(additional_queries, 1):
            print(f"  {i}. {query}")

        if additional_queries:
            print(f"\nâœ… è¿½åŠ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒ {len(additional_queries)} å€‹ç”Ÿæˆã•ã‚Œã¾ã—ãŸ")

            # æœŸå¾…ã•ã‚Œã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã®æ¯”è¼ƒ
            expected_keywords = ["å¸‚å ´è¦æ¨¡", "AIè¦åˆ¶", "å€«ç†ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³", "é›‡ç”¨å½±éŸ¿", "åŒ»ç™‚AI"]
            matched = [q for q in additional_queries if any(exp in q for exp in expected_keywords)]
            print(f"æœŸå¾…ã•ã‚Œã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã®ä¸€è‡´: {len(matched)}/{len(expected_keywords)}")

            # æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®æ¤œè¨¼
            if len(additional_queries) <= 5:
                print("âœ… ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ãŒåˆ¶é™å†…ï¼ˆæœ€å¤§5å€‹ï¼‰")
            else:
                print("âŒ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ãŒåˆ¶é™ã‚’è¶…ãˆã¦ã„ã¾ã™")

            # ç„¡åŠ¹ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒã‚§ãƒƒã‚¯
            invalid_keywords = [q for q in additional_queries if any(invalid in q.lower() for invalid in [
                'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰', 'è¿½åŠ ', 'ææ¡ˆ', 'ä»¥ä¸‹ã®', 'å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰'
            ])]
            if not invalid_keywords:
                print("âœ… ç„¡åŠ¹ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            else:
                print(f"âŒ ç„¡åŠ¹ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {invalid_keywords}")

        else:
            print("\nâŒ è¿½åŠ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

def test_structured_analysis():
    """æ§‹é€ åŒ–åˆ†æã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ“Š æ§‹é€ åŒ–åˆ†æãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    try:
        # DeepResearchã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        researcher = DeepResearch("ollama")

        # ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã«ç½®ãæ›ãˆ
        researcher.model = MockStructuredLanguageModel()

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        query = "AIæŠ€è¡“ã®æœ€æ–°å‹•å‘"
        search_results = [
            type('SearchResult', (), {
                'title': '2024å¹´AIæŠ€è¡“ã®é€²æ­©',
                'url': 'https://example.com/ai-2024',
                'snippet': '2024å¹´ã«AIæŠ€è¡“ãŒå¤§å¹…ã«é€²æ­©ã—ãŸ',
                'date_info': '2024å¹´',
                'reliability_score': 0.9,
                'source_type': 'news'
            })(),
            type('SearchResult', (), {
                'title': 'ä¼æ¥­ã®AIå°å…¥çŠ¶æ³',
                'url': 'https://example.com/ai-adoption',
                'snippet': 'ä¼æ¥­å°å…¥ç‡ã¯60%ã«é”ã—ãŸ',
                'date_info': '2024å¹´',
                'reliability_score': 0.8,
                'source_type': 'research'
            })()
        ]

        print(f"ã‚¯ã‚¨ãƒª: {query}")
        print(f"æ¤œç´¢çµæœæ•°: {len(search_results)}")
        print()

        # æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§åˆ†æã‚’ç”Ÿæˆ
        analysis = researcher._analyze_results(query, search_results)

        print("ç”Ÿæˆã•ã‚ŒãŸåˆ†æ:")
        print(analysis)

        if analysis:
            print(f"\nâœ… åˆ†æãŒæ­£å¸¸ã«ç”Ÿæˆã•ã‚Œã¾ã—ãŸ")

            # åˆ†æå†…å®¹ã®æ¤œè¨¼
            if "ä¸»è¦ãªäº‹å®Ÿ" in analysis:
                print("âœ… ä¸»è¦ãªäº‹å®Ÿã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
            else:
                print("âŒ ä¸»è¦ãªäº‹å®Ÿã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")

            if "å…·ä½“çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ" in analysis:
                print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
            else:
                print("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")

        else:
            print("\nâŒ åˆ†æãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

def test_structured_summary():
    """æ§‹é€ åŒ–è¦ç´„ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ“ æ§‹é€ åŒ–è¦ç´„ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    try:
        # DeepResearchã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        researcher = DeepResearch("ollama")

        # ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã«ç½®ãæ›ãˆ
        researcher.model = MockStructuredLanguageModel()

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        query = "AIæŠ€è¡“ã®æœ€æ–°å‹•å‘"
        analysis = """
ä¸»è¦ãªäº‹å®Ÿ:
1. 2024å¹´ã«AIæŠ€è¡“ãŒå¤§å¹…ã«é€²æ­©ã—ãŸ
2. å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãŒå‘ä¸Šã—ãŸ
3. ä¼æ¥­å°å…¥ãŒåŠ é€Ÿã—ã¦ã„ã‚‹

å…·ä½“çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ:
1. å¸‚å ´è¦æ¨¡ã¯å‰å¹´æ¯”30%å¢—åŠ 
2. ä¼æ¥­å°å…¥ç‡ã¯60%ã«é”ã—ãŸ

çµè«–: AIæŠ€è¡“ã¯æ€¥é€Ÿã«ç™ºå±•ã—ã¦ã„ã‚‹ãŒã€è¦åˆ¶ã‚„å€«ç†é¢ã§ã®èª²é¡Œã‚‚å­˜åœ¨ã™ã‚‹
"""

        print(f"ã‚¯ã‚¨ãƒª: {query}")
        print(f"åˆ†æçµæœ: {analysis[:100]}...")
        print()

        # æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§è¦ç´„ã‚’ç”Ÿæˆ
        summary = researcher._create_summary(query, analysis)

        print("ç”Ÿæˆã•ã‚ŒãŸè¦ç´„:")
        print(summary)

        if summary:
            print(f"\nâœ… è¦ç´„ãŒæ­£å¸¸ã«ç”Ÿæˆã•ã‚Œã¾ã—ãŸ")

            # è¦ç´„å†…å®¹ã®æ¤œè¨¼
            if "é‡è¦ãªäº‹å®Ÿ" in summary:
                print("âœ… é‡è¦ãªäº‹å®Ÿã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
            else:
                print("âŒ é‡è¦ãªäº‹å®Ÿã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")

            if "çµè«–" in summary:
                print("âœ… çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
            else:
                print("âŒ çµè«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")

        else:
            print("\nâŒ è¦ç´„ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

def test_pydantic_models():
    """Pydanticãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ”§ Pydanticãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    try:
        # AdditionalQueriesResponseã®ãƒ†ã‚¹ãƒˆ
        print("1. AdditionalQueriesResponseãƒ†ã‚¹ãƒˆ")
        valid_keywords = ["å¸‚å ´è¦æ¨¡", "AIè¦åˆ¶", "å€«ç†ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³"]
        response = AdditionalQueriesResponse(keywords=valid_keywords)
        print(f"   âœ… æœ‰åŠ¹ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {response.keywords}")

        # ç„¡åŠ¹ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒ†ã‚¹ãƒˆ
        try:
            invalid_keywords = ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "è¿½åŠ ææ¡ˆ", "ä»¥ä¸‹ã®å†…å®¹"]
            response = AdditionalQueriesResponse(keywords=invalid_keywords)
            print(f"   âŒ ç„¡åŠ¹ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå—ã‘å…¥ã‚Œã‚‰ã‚Œã¾ã—ãŸ: {response.keywords}")
        except Exception as e:
            print(f"   âœ… ç„¡åŠ¹ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒé©åˆ‡ã«æ‹’å¦ã•ã‚Œã¾ã—ãŸ: {e}")

        # AnalysisResponseã®ãƒ†ã‚¹ãƒˆ
        print("\n2. AnalysisResponseãƒ†ã‚¹ãƒˆ")
        analysis_data = {
            "main_facts": ["äº‹å®Ÿ1", "äº‹å®Ÿ2"],
            "data_statistics": ["çµ±è¨ˆ1"],
            "different_perspectives": ["è¦–ç‚¹1"],
            "date_analysis": ["æ—¥ä»˜åˆ†æ1"],
            "unknown_points": ["ä¸æ˜ç‚¹1"]
        }
        analysis = AnalysisResponse(**analysis_data)
        print(f"   âœ… åˆ†æãƒ¬ã‚¹ãƒãƒ³ã‚¹: {len(analysis.main_facts)}å€‹ã®ä¸»è¦äº‹å®Ÿ")

        # ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ã®ãƒ†ã‚¹ãƒˆ
        text = analysis.to_text()
        print(f"   âœ… ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›: {len(text)}æ–‡å­—")

        # SummaryResponseã®ãƒ†ã‚¹ãƒˆ
        print("\n3. SummaryResponseãƒ†ã‚¹ãƒˆ")
        summary_data = {
            "key_facts": ["é‡è¦äº‹å®Ÿ1", "é‡è¦äº‹å®Ÿ2", "é‡è¦äº‹å®Ÿ3"],
            "conclusion": "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆçµè«–ã§ã™",
            "date_summary": "2024å¹´ã®æƒ…å ±"
        }
        summary = SummaryResponse(**summary_data)
        print(f"   âœ… è¦ç´„ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {len(summary.key_facts)}å€‹ã®é‡è¦äº‹å®Ÿ")

        # ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ã®ãƒ†ã‚¹ãƒˆ
        text = summary.to_text()
        print(f"   âœ… ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›: {len(text)}æ–‡å­—")

        print("\nğŸ‰ å…¨ã¦ã®Pydanticãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸ§ª æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    # Pydanticãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ
    test_pydantic_models()

    # æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ†ã‚¹ãƒˆ
    test_structured_additional_queries()
    test_structured_analysis()
    test_structured_summary()

    print("\nğŸ‰ å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    main()
