#!/usr/bin/env python3
"""
è¿½åŠ æ¤œç´¢æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from main import DeepResearch

class MockLanguageModel:
    """ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¢ãƒƒã‚¯è¨€èªãƒ¢ãƒ‡ãƒ«"""

    def generate(self, prompt: str) -> str:
        """ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™"""
        if "è¿½åŠ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰" in prompt:
            return """
å¸‚å ´è¦æ¨¡ çµ±è¨ˆ
AIè¦åˆ¶ æ³•å¾‹
å€«ç†ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
é›‡ç”¨å½±éŸ¿ èª¿æŸ»
åŒ»ç™‚AI å¿œç”¨
"""
        elif "åˆ†æ" in prompt:
            return "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆç”¨ã®åˆ†æçµæœã§ã™ã€‚"
        elif "è¦ç´„" in prompt:
            return "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆç”¨ã®è¦ç´„ã§ã™ã€‚"
        else:
            return "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§ã™ã€‚"

def test_additional_queries():
    """è¿½åŠ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª è¿½åŠ æ¤œç´¢æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)

    # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
    original_query = "äººå·¥çŸ¥èƒ½ã®æœ€æ–°å‹•å‘"
    analysis = """
    æ¤œç´¢çµæœã‹ã‚‰ä»¥ä¸‹ã®äº‹å®ŸãŒç¢ºèªã•ã‚Œã¾ã—ãŸï¼š

    1. 2024å¹´ã«ãŠã‘ã‚‹äººå·¥çŸ¥èƒ½ã®ä¸»è¦ãªé€²å±•
    - å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Š
    - ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«AIã®å®Ÿç”¨åŒ–
    - ç”ŸæˆAIã®ä¼æ¥­å°å…¥ãŒåŠ é€Ÿ

    2. æŠ€è¡“çš„ãªèª²é¡Œ
    - ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³å•é¡Œ
    - ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®æ‡¸å¿µ
    - è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã®å¤§é‡æ¶ˆè²»

    3. ç¤¾ä¼šçš„å½±éŸ¿
    - é›‡ç”¨ã¸ã®å½±éŸ¿
    - æ•™è‚²åˆ†é‡ã§ã®æ´»ç”¨
    - åŒ»ç™‚åˆ†é‡ã§ã®å¿œç”¨

    æ¤œç´¢çµæœã‹ã‚‰ã¯ä¸æ˜ãªç‚¹ï¼š
    - å…·ä½“çš„ãªå¸‚å ´è¦æ¨¡ã®æ•°å€¤
    - å„å›½ã®è¦åˆ¶å‹•å‘
    - å€«ç†çš„ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã®è©³ç´°
    """

    summary = """
    äººå·¥çŸ¥èƒ½ã¯2024å¹´ã«å¤§ããªé€²å±•ã‚’é‚ã’ã€ç‰¹ã«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¨ç”ŸæˆAIã®å®Ÿç”¨åŒ–ãŒåŠ é€Ÿã—ã¦ã„ã¾ã™ã€‚
    ã—ã‹ã—ã€ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚„ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼å•é¡Œãªã©ã®æŠ€è¡“çš„èª²é¡Œã‚‚å­˜åœ¨ã—ã¾ã™ã€‚
    ç¤¾ä¼šçš„å½±éŸ¿ã¨ã—ã¦ã¯é›‡ç”¨ã¸ã®å½±éŸ¿ãŒæ‡¸å¿µã•ã‚Œã¦ã„ã¾ã™ãŒã€æ•™è‚²ã‚„åŒ»ç™‚åˆ†é‡ã§ã®æ´»ç”¨ã‚‚é€²ã‚“ã§ã„ã¾ã™ã€‚
    """

    try:
        # DeepResearchã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        researcher = DeepResearch("ollama")

        # ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã«ç½®ãæ›ãˆ
        researcher.review_model = MockLanguageModel()

        print(f"å…ƒã®ã‚¯ã‚¨ãƒª: {original_query}")
        print(f"åˆ†æçµæœ: {analysis[:200]}...")
        print(f"è¦ç´„: {summary[:200]}...")
        print()

        # è¿½åŠ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
        additional_queries = researcher._generate_additional_queries(
            original_query, analysis, summary
        )

        print("ç”Ÿæˆã•ã‚ŒãŸè¿½åŠ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:")
        for i, query in enumerate(additional_queries, 1):
            print(f"  {i}. {query}")

        if additional_queries:
            print(f"\nâœ… è¿½åŠ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒ {len(additional_queries)} å€‹ç”Ÿæˆã•ã‚Œã¾ã—ãŸ")

            # æœŸå¾…ã•ã‚Œã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã®æ¯”è¼ƒ
            expected_keywords = ["å¸‚å ´è¦æ¨¡", "AIè¦åˆ¶", "å€«ç†ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³", "é›‡ç”¨å½±éŸ¿", "åŒ»ç™‚AI"]
            matched = [q for q in additional_queries if any(exp in q for exp in expected_keywords)]
            print(f"æœŸå¾…ã•ã‚Œã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã®ä¸€è‡´: {len(matched)}/{len(expected_keywords)}")

        else:
            print("\nâŒ è¿½åŠ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def test_date_extraction():
    """æ—¥ä»˜æŠ½å‡ºæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ“… æ—¥ä»˜æŠ½å‡ºæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)

    from main import WebSearcher, Config

    config = Config()
    searcher = WebSearcher(config)

    test_cases = [
        ("2024å¹´æœ€æ–°ã®AIæŠ€è¡“", "2024å¹´ã«ãŠã‘ã‚‹äººå·¥çŸ¥èƒ½ã®æœ€æ–°å‹•å‘ã«ã¤ã„ã¦"),
        ("2023å¹´12æœˆã®å¸‚å ´å‹•å‘", "2023å¹´12æœˆã«ç™ºè¡¨ã•ã‚ŒãŸå¸‚å ´èª¿æŸ»çµæœ"),
        ("2024-01-15ã®ç™ºè¡¨", "2024å¹´1æœˆ15æ—¥ã«é–‹å‚¬ã•ã‚ŒãŸä¼šè­°ã§ã®ç™ºè¡¨å†…å®¹"),
        ("2024/02/20ã®è¨˜äº‹", "2024å¹´2æœˆ20æ—¥ã«å…¬é–‹ã•ã‚ŒãŸæŠ€è¡“è¨˜äº‹"),
        ("3æœˆ15æ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹", "3æœˆ15æ—¥ã«å ±é“ã•ã‚ŒãŸæœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹"),
        ("2023å¹´ã®çµ±è¨ˆ", "2023å¹´ã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿"),
        ("æ—¥ä»˜ãªã—ã®ã‚¿ã‚¤ãƒˆãƒ«", "æ—¥ä»˜æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ãªã„ã‚¿ã‚¤ãƒˆãƒ«"),
    ]

    success_count = 0
    for title, snippet in test_cases:
        date_info = searcher._extract_date_info(title, snippet)
        print(f"ã‚¿ã‚¤ãƒˆãƒ«: {title}")
        print(f"ã‚¹ãƒ‹ãƒšãƒƒãƒˆ: {snippet}")
        print(f"æŠ½å‡ºã•ã‚ŒãŸæ—¥ä»˜: {date_info or 'ãªã—'}")

        # æœŸå¾…ã•ã‚Œã‚‹çµæœã¨ã®æ¯”è¼ƒ
        expected = None
        if "2024å¹´æœ€æ–°" in title:
            expected = "2024å¹´"
        elif "2023å¹´12æœˆ" in title:
            expected = "2023å¹´12æœˆ"
        elif "2024-01-15" in title:
            expected = "2024å¹´1æœˆ15æ—¥"
        elif "2024/02/20" in title:
            expected = "2024å¹´2æœˆ20æ—¥"
        elif "3æœˆ15æ—¥" in title:
            expected = "3æœˆ15æ—¥"
        elif "2023å¹´" in title:
            expected = "2023å¹´"

        if date_info == expected:
            print("âœ… æ­£ã—ãæŠ½å‡ºã•ã‚Œã¾ã—ãŸ")
            success_count += 1
        else:
            print(f"âŒ æœŸå¾…å€¤: {expected}")

        print("-" * 30)

    print(f"æ—¥ä»˜æŠ½å‡ºæˆåŠŸç‡: {success_count}/{len(test_cases)}")

def test_hallucination_prevention():
    """ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³é˜²æ­¢æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ›¡ï¸ ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³é˜²æ­¢æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³é˜²æ­¢ã®æ–‡è¨€ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    from main import DeepResearch

    researcher = DeepResearch("ollama")

    # åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒã‚§ãƒƒã‚¯
    analysis_prompt = researcher._analyze_results("ãƒ†ã‚¹ãƒˆ", [])
    if "æ¤œç´¢çµæœã«å«ã¾ã‚Œã¦ã„ãªã„æƒ…å ±ã¯æ¨æ¸¬ã›ãš" in analysis_prompt:
        print("âœ… åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³é˜²æ­¢æ–‡è¨€ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
    else:
        print("âŒ åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³é˜²æ­¢æ–‡è¨€ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")

    # è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒã‚§ãƒƒã‚¯
    summary_prompt = researcher._create_summary("ãƒ†ã‚¹ãƒˆ", "ãƒ†ã‚¹ãƒˆåˆ†æ")
    if "äº‹å®Ÿã®ã¿ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„" in summary_prompt:
        print("âœ… è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³é˜²æ­¢æ–‡è¨€ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
    else:
        print("âŒ è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³é˜²æ­¢æ–‡è¨€ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")

    # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒã‚§ãƒƒã‚¯
    final_prompt = researcher._create_final_report("ãƒ†ã‚¹ãƒˆ", "ãƒ†ã‚¹ãƒˆåˆ†æ", "ãƒ†ã‚¹ãƒˆè¦ç´„")
    if "äº‹å®Ÿã®ã¿ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„" in final_prompt:
        print("âœ… æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³é˜²æ­¢æ–‡è¨€ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
    else:
        print("âŒ æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³é˜²æ­¢æ–‡è¨€ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")

def test_markdown_links():
    """ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒªãƒ³ã‚¯æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ”— ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒªãƒ³ã‚¯æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)

    from main import SearchResult, Citation, ResearchResult, DeepResearch

    # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
    search_results = [
        SearchResult(
            title="ãƒ†ã‚¹ãƒˆè¨˜äº‹1",
            url="https://example.com/article1",
            snippet="ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆè¨˜äº‹1ã®å†…å®¹ã§ã™ã€‚",
            search_query="ãƒ†ã‚¹ãƒˆ",
            date_info="2024å¹´"
        ),
        SearchResult(
            title="ãƒ†ã‚¹ãƒˆè¨˜äº‹2",
            url="https://example.com/article2",
            snippet="ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆè¨˜äº‹2ã®å†…å®¹ã§ã™ã€‚",
            search_query="ãƒ†ã‚¹ãƒˆ",
            date_info="2023å¹´"
        )
    ]

    citations = [
        Citation(
            source_title="ãƒ†ã‚¹ãƒˆè¨˜äº‹1",
            source_url="https://example.com/article1",
            content="ãƒ†ã‚¹ãƒˆè¨˜äº‹1ã®å†…å®¹",
            search_query="ãƒ†ã‚¹ãƒˆ",
            relevance_score=1.0,
            date_info="2024å¹´"
        ),
        Citation(
            source_title="ãƒ†ã‚¹ãƒˆè¨˜äº‹2",
            source_url="https://example.com/article2",
            content="ãƒ†ã‚¹ãƒˆè¨˜äº‹2ã®å†…å®¹",
            search_query="ãƒ†ã‚¹ãƒˆ",
            relevance_score=0.8,
            date_info="2023å¹´"
        )
    ]

    result = ResearchResult(
        query="ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª",
        search_results=search_results,
        analysis="ãƒ†ã‚¹ãƒˆåˆ†æ",
        summary="ãƒ†ã‚¹ãƒˆè¦ç´„",
        citations=citations,
        additional_queries=["è¿½åŠ ã‚¯ã‚¨ãƒª1", "è¿½åŠ ã‚¯ã‚¨ãƒª2"],
        final_report="ã“ã‚Œã¯[1]ã«åŸºã¥ããƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã§ã™ã€‚[2]ã‚‚å‚è€ƒã«ã—ã¾ã—ãŸã€‚"
    )

    # DeepResearchã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
    researcher = DeepResearch("gemini")

    # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    filename = researcher.save_to_markdown(result, "test_output.md")

    # ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç¢ºèª
    with open(filename, 'r', encoding='utf-8') as f:
        content = f.read()

    # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒªãƒ³ã‚¯ãŒæ­£ã—ãç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if "[ãƒ†ã‚¹ãƒˆè¨˜äº‹1](https://example.com/article1)" in content:
        print("âœ… æ¤œç´¢çµæœã®ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒªãƒ³ã‚¯ãŒæ­£ã—ãç”Ÿæˆã•ã‚Œã¦ã„ã¾ã™")
    else:
        print("âŒ æ¤œç´¢çµæœã®ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒªãƒ³ã‚¯ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")

    if "[ãƒ†ã‚¹ãƒˆè¨˜äº‹1](https://example.com/article1)ï¼ˆ2024å¹´ï¼‰" in content:
        print("âœ… å¼•ç”¨æ–‡çŒ®ã®ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒªãƒ³ã‚¯ãŒæ­£ã—ãç”Ÿæˆã•ã‚Œã¦ã„ã¾ã™")
    else:
        print("âŒ å¼•ç”¨æ–‡çŒ®ã®ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒªãƒ³ã‚¯ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")

    if "[1](https://example.com/article1)" in content:
        print("âœ… ãƒ¬ãƒãƒ¼ãƒˆå†…ã®å¼•ç”¨ãƒªãƒ³ã‚¯ãŒæ­£ã—ãç”Ÿæˆã•ã‚Œã¦ã„ã¾ã™")
    else:
        print("âŒ ãƒ¬ãƒãƒ¼ãƒˆå†…ã®å¼•ç”¨ãƒªãƒ³ã‚¯ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")

    # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    os.remove(filename)
    print("âœ… ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")

def test_integrated_report():
    """çµ±åˆãƒ¬ãƒãƒ¼ãƒˆæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ“‹ çµ±åˆãƒ¬ãƒãƒ¼ãƒˆæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)

    from main import DeepResearch

    researcher = DeepResearch("gemini")

    # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒã‚§ãƒƒã‚¯
    final_prompt = researcher._create_final_report("ãƒ†ã‚¹ãƒˆ", "ãƒ†ã‚¹ãƒˆåˆ†æ", "ãƒ†ã‚¹ãƒˆè¦ç´„")

    if "çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ" in final_prompt:
        print("âœ… çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã®ç”ŸæˆæŒ‡ç¤ºãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
    else:
        print("âŒ çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã®ç”ŸæˆæŒ‡ç¤ºãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")

    if "åˆ©ç”¨å¯èƒ½ãªæƒ…å ±æº" in final_prompt:
        print("âœ… æƒ…å ±æºã®æ˜ç¤ºãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
    else:
        print("âŒ æƒ…å ±æºã®æ˜ç¤ºãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")

    if "[1], [2] ã®å½¢å¼" in final_prompt:
        print("âœ… å¼•ç”¨å½¢å¼ã®æŒ‡å®šãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
    else:
        print("âŒ å¼•ç”¨å½¢å¼ã®æŒ‡å®šãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")

def test_date_relative_analysis():
    """ç›¸å¯¾çš„ãªæ—¥ä»˜åˆ†ææ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ“… ç›¸å¯¾çš„æ—¥ä»˜åˆ†ææ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)

    from main import DeepResearch

    researcher = DeepResearch("gemini")

    # ä»Šæ—¥ã®æ—¥ä»˜ã‚’ç¢ºèª
    print(f"ä»Šæ—¥ã®æ—¥ä»˜: {researcher.today_date}")

    # æ§˜ã€…ãªæ—¥ä»˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ†ã‚¹ãƒˆ
    test_dates = [
        ("2024å¹´1æœˆ15æ—¥", "éå»ã®æ—¥ä»˜"),
        ("2024å¹´12æœˆ31æ—¥", "å°†æ¥ã®æ—¥ä»˜"),
        ("2024å¹´", "å¹´ã®ã¿"),
        ("3æœˆ15æ—¥", "æœˆæ—¥ã®ã¿"),
        ("2023å¹´12æœˆ", "å¹´æœˆã®ã¿"),
        ("2024-01-15", "ãƒã‚¤ãƒ•ãƒ³åŒºåˆ‡ã‚Š"),
        ("2024/01/15", "ã‚¹ãƒ©ãƒƒã‚·ãƒ¥åŒºåˆ‡ã‚Š"),
        ("", "æ—¥ä»˜ãªã—"),
        ("ä¸æ˜ãªå½¢å¼", "ä¸æ˜ãªå½¢å¼"),
    ]

    for date_str, description in test_dates:
        result = researcher._parse_date_info(date_str)
        print(f"{description}: {date_str} â†’ {result.get('relative_info', 'è§£æå¤±æ•—')}")

        if result.get('is_valid', False):
            if result.get('is_future', False):
                print(f"  â†’ å°†æ¥ã®äºˆå®š")
            elif result.get('is_recent', False):
                print(f"  â†’ æœ€è¿‘ã®æƒ…å ±")
            else:
                print(f"  â†’ éå»ã®æƒ…å ±")

    print("âœ… ç›¸å¯¾çš„æ—¥ä»˜åˆ†ææ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆå®Œäº†")

def test_date_integration():
    """æ—¥ä»˜æƒ…å ±ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ”„ æ—¥ä»˜æƒ…å ±çµ±åˆãƒ†ã‚¹ãƒˆ")
    print("=" * 50)

    from main import DeepResearch, SearchResult

    researcher = DeepResearch("gemini")

    # ãƒ†ã‚¹ãƒˆç”¨ã®æ¤œç´¢çµæœã‚’ä½œæˆ
    test_results = [
        SearchResult(
            title="2024å¹´1æœˆç™ºå£²äºˆå®šã®è£½å“",
            url="https://example.com/product1",
            snippet="2024å¹´1æœˆã«ç™ºå£²äºˆå®šã®æ–°è£½å“ã«ã¤ã„ã¦",
            search_query="ãƒ†ã‚¹ãƒˆ",
            date_info="2024å¹´1æœˆ15æ—¥"
        ),
        SearchResult(
            title="2024å¹´12æœˆã®ç™ºè¡¨",
            url="https://example.com/announcement",
            snippet="2024å¹´12æœˆã«ç™ºè¡¨äºˆå®šã®æ–°æŠ€è¡“",
            search_query="ãƒ†ã‚¹ãƒˆ",
            date_info="2024å¹´12æœˆ31æ—¥"
        ),
        SearchResult(
            title="2023å¹´ã®çµ±è¨ˆ",
            url="https://example.com/stats",
            snippet="2023å¹´ã®å¸‚å ´çµ±è¨ˆãƒ‡ãƒ¼ã‚¿",
            search_query="ãƒ†ã‚¹ãƒˆ",
            date_info="2023å¹´"
        )
    ]

    # åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
    analysis_prompt = researcher._analyze_results("ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª", test_results)

    # ä»Šæ—¥ã®æ—¥ä»˜æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if "ä»Šæ—¥ã®æ—¥ä»˜" in analysis_prompt:
        print("âœ… ä»Šæ—¥ã®æ—¥ä»˜æƒ…å ±ãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã¾ã‚Œã¦ã„ã¾ã™")
    else:
        print("âŒ ä»Šæ—¥ã®æ—¥ä»˜æƒ…å ±ãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")

    # ç›¸å¯¾çš„ãªæ—¥ä»˜æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if "â†’" in analysis_prompt and ("æ—¥å‰" in analysis_prompt or "æ—¥å¾Œ" in analysis_prompt or "éå»ã®æƒ…å ±" in analysis_prompt or "å°†æ¥ã®äºˆå®š" in analysis_prompt):
        print("âœ… ç›¸å¯¾çš„ãªæ—¥ä»˜æƒ…å ±ãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã¾ã‚Œã¦ã„ã¾ã™")
    else:
        print("âŒ ç›¸å¯¾çš„ãªæ—¥ä»˜æƒ…å ±ãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")

    # è¿½åŠ æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ
    additional_prompt = researcher._generate_additional_queries("ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª", "ãƒ†ã‚¹ãƒˆåˆ†æ", "ãƒ†ã‚¹ãƒˆè¦ç´„")

    if "ä»Šæ—¥ã®æ—¥ä»˜" in additional_prompt:
        print("âœ… è¿½åŠ æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆã«ä»Šæ—¥ã®æ—¥ä»˜æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
    else:
        print("âŒ è¿½åŠ æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆã«ä»Šæ—¥ã®æ—¥ä»˜æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")

    if "ç™ºå£²äºˆå®šæ—¥" in additional_prompt or "æœ€æ–°çŠ¶æ³" in additional_prompt:
        print("âœ… å¤ã„æƒ…å ±ã®æœ€æ–°çŠ¶æ³ç¢ºèªæŒ‡ç¤ºãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
    else:
        print("âŒ å¤ã„æƒ…å ±ã®æœ€æ–°çŠ¶æ³ç¢ºèªæŒ‡ç¤ºãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")

def test_enhanced_date_extraction():
    """å¼·åŒ–ã•ã‚ŒãŸæ—¥ä»˜æŠ½å‡ºæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ“… å¼·åŒ–ã•ã‚ŒãŸæ—¥ä»˜æŠ½å‡ºæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)

    from main import WebSearcher, Config

    searcher = WebSearcher(Config())

    test_cases = [
        # è‹±èªå½¢å¼
        ("Jan 15, 2024", "January 15, 2024ã®è¨˜äº‹"),
        ("Feb 20, 2023", "February 20, 2023ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹"),
        ("15 Mar 2024", "March 15, 2024ã®ç™ºè¡¨"),

        # ç›¸å¯¾çš„ãªæ—¥ä»˜è¡¨ç¾
        ("ä»Šæ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹", "ä»Šæ—¥ç™ºè¡¨ã•ã‚ŒãŸæœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹"),
        ("æ˜¨æ—¥ã®è¨˜äº‹", "æ˜¨æ—¥å…¬é–‹ã•ã‚ŒãŸè¨˜äº‹"),
        ("æ˜æ—¥ã®ä¼šè­°", "æ˜æ—¥é–‹å‚¬ã•ã‚Œã‚‹ä¼šè­°"),
        ("ä»Šé€±ã®ç™ºè¡¨", "ä»Šé€±äºˆå®šã•ã‚Œã¦ã„ã‚‹ç™ºè¡¨"),
        ("å…ˆé€±ã®çµ±è¨ˆ", "å…ˆé€±ç™ºè¡¨ã•ã‚ŒãŸçµ±è¨ˆãƒ‡ãƒ¼ã‚¿"),
        ("æ¥é€±ã®ã‚¤ãƒ™ãƒ³ãƒˆ", "æ¥é€±é–‹å‚¬ã•ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ"),
        ("ä»Šæœˆã®å‹•å‘", "ä»Šæœˆã®å¸‚å ´å‹•å‘"),
        ("å…ˆæœˆã®çµæœ", "å…ˆæœˆã®æ¥­ç¸¾çµæœ"),
        ("æ¥æœˆã®äºˆå®š", "æ¥æœˆã®äºˆå®š"),
        ("ä»Šå¹´ã®ç›®æ¨™", "ä»Šå¹´ã®ç›®æ¨™"),
        ("å»å¹´ã®å®Ÿç¸¾", "å»å¹´ã®å®Ÿç¸¾"),
        ("æ¥å¹´ã®è¨ˆç”»", "æ¥å¹´ã®è¨ˆç”»"),
        ("3æ—¥å‰ã®ç™ºè¡¨", "3æ—¥å‰ã«ç™ºè¡¨ã•ã‚ŒãŸå†…å®¹"),
        ("2é€±é–“å‰ã®è¨˜äº‹", "2é€±é–“å‰ã«å…¬é–‹ã•ã‚ŒãŸè¨˜äº‹"),
        ("1ãƒ¶æœˆå‰ã®çµ±è¨ˆ", "1ãƒ¶æœˆå‰ã«ç™ºè¡¨ã•ã‚ŒãŸçµ±è¨ˆ"),
        ("5å¹´å‰ã®èª¿æŸ»", "5å¹´å‰ã«å®Ÿæ–½ã•ã‚ŒãŸèª¿æŸ»"),

        # è¤‡é›‘ãªå½¢å¼
        ("2024-01-15ã®ç™ºè¡¨", "2024å¹´1æœˆ15æ—¥ã«é–‹å‚¬ã•ã‚ŒãŸä¼šè­°ã§ã®ç™ºè¡¨å†…å®¹"),
        ("2024/02/20ã®è¨˜äº‹", "2024å¹´2æœˆ20æ—¥ã«å…¬é–‹ã•ã‚ŒãŸæŠ€è¡“è¨˜äº‹"),
        ("03-15-2024ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹", "3æœˆ15æ—¥ã«å ±é“ã•ã‚ŒãŸæœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹"),
        ("12/25/2023ã®çµ±è¨ˆ", "2023å¹´12æœˆ25æ—¥ã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿"),
    ]

    success_count = 0
    for title, snippet in test_cases:
        extracted_date = searcher._extract_date_info(title, snippet)
        print(f"ã‚¿ã‚¤ãƒˆãƒ«: {title}")
        print(f"ã‚¹ãƒ‹ãƒšãƒƒãƒˆ: {snippet}")
        print(f"æŠ½å‡ºã•ã‚ŒãŸæ—¥ä»˜: {extracted_date}")
        if extracted_date:
            print("âœ… æ­£ã—ãæŠ½å‡ºã•ã‚Œã¾ã—ãŸ")
            success_count += 1
        else:
            print("âŒ æŠ½å‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        print("-" * 30)

    print(f"æ—¥ä»˜æŠ½å‡ºæˆåŠŸç‡: {success_count}/{len(test_cases)}")

def test_academic_quality_prompts():
    """å­¦è¡“çš„å“è³ªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ“ å­¦è¡“çš„å“è³ªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚¹ãƒˆ")
    print("=" * 50)

    from main import DeepResearch

    researcher = DeepResearch("gemini")

    # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒã‚§ãƒƒã‚¯
    final_prompt = researcher._create_final_report("ãƒ†ã‚¹ãƒˆ", "ãƒ†ã‚¹ãƒˆåˆ†æ", "ãƒ†ã‚¹ãƒˆè¦ç´„")

    academic_elements = [
        "æ™‚ç³»åˆ—ã®æ­£ç¢ºãªç†è§£",
        "æƒ…å ±æºã®ä¿¡é ¼æ€§è©•ä¾¡",
        "æ‰¹åˆ¤çš„æ€è€ƒã¨å¤šè§’çš„åˆ†æ",
        "å­¦è¡“çš„å³å¯†æ€§",
        "éå»ã®äº‹å®Ÿã€ç¾åœ¨ã®çŠ¶æ³ã€å°†æ¥ã®äºˆå®šã‚’åŒºåˆ¥",
        "ä¸€æ¬¡æƒ…å ±ã¨äºŒæ¬¡æƒ…å ±ã‚’åŒºåˆ¥",
        "æƒ…å ±ã®åã‚Šã‚„é™ç•Œã‚’æ˜è¨˜",
        "åå¯¾æ„è¦‹ã‚„ç•°è«–ã‚‚å«ã‚ã¦æ¤œè¨",
        "æƒ…å ±ã®çŸ›ç›¾ç‚¹ã‚„ä¸ç¢ºå®Ÿæ€§ã‚’æ˜è¨˜",
        "äº‹å®Ÿã¨æ¨æ¸¬ã‚’æ˜ç¢ºã«åŒºåˆ¥",
        "é©åˆ‡ãªå¼•ç”¨ã¨å‡ºå…¸ã®æ˜è¨˜",
        "è«–ç†çš„ãªæ§‹æˆã¨å®¢è¦³çš„ãªè¨˜è¿°"
    ]

    found_elements = 0
    for element in academic_elements:
        if element in final_prompt:
            print(f"âœ… {element} ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
            found_elements += 1
        else:
            print(f"âŒ {element} ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")

    print(f"\nå­¦è¡“çš„è¦ç´ ã®åŒ…å«ç‡: {found_elements}/{len(academic_elements)}")

def test_reliability_evaluation():
    """ä¿¡é ¼æ€§è©•ä¾¡æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ” ä¿¡é ¼æ€§è©•ä¾¡æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)

    from main import WebSearcher, Config

    # è¨­å®šã‚’èª­ã¿è¾¼ã¿
    config = Config()
    searcher = WebSearcher(config)

    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_cases = [
        {
            "url": "https://www.nhk.or.jp/news/article1.html",
            "title": "NHKãƒ‹ãƒ¥ãƒ¼ã‚¹: å…¬å¼ç™ºè¡¨",
            "snippet": "æ”¿åºœãŒå…¬å¼ã«ç™ºè¡¨ã—ãŸå†…å®¹",
            "expected_type": "news",
            "expected_min_score": 0.7
        },
        {
            "url": "https://www.gov.jp/press/2024/01/01.html",
            "title": "æ”¿åºœç™ºè¡¨",
            "snippet": "æ”¿åºœã®å…¬å¼ç™ºè¡¨",
            "expected_type": "official",
            "expected_min_score": 0.8
        },
        {
            "url": "https://example.blog.com/rumor.html",
            "title": "å™‚è©±",
            "snippet": "æœªç¢ºèªã®å™‚è©±",
            "expected_type": "blog",
            "expected_min_score": 0.0
        }
    ]

    for i, case in enumerate(test_cases, 1):
        result = searcher._evaluate_source_reliability(
            case["url"], case["title"], case["snippet"]
        )

        print(f"\nãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i}:")
        print(f"URL: {case['url']}")
        print(f"æœŸå¾…ã•ã‚Œã‚‹ã‚¿ã‚¤ãƒ—: {case['expected_type']}")
        print(f"å®Ÿéš›ã®ã‚¿ã‚¤ãƒ—: {result['source_type']}")
        print(f"æœŸå¾…ã•ã‚Œã‚‹æœ€å°ã‚¹ã‚³ã‚¢: {case['expected_min_score']}")
        print(f"å®Ÿéš›ã®ã‚¹ã‚³ã‚¢: {result['reliability_score']:.2f}")

        if result['source_type'] == case['expected_type']:
            print("âœ… ã‚¿ã‚¤ãƒ—åˆ¤å®š: æˆåŠŸ")
        else:
            print("âŒ ã‚¿ã‚¤ãƒ—åˆ¤å®š: å¤±æ•—")

        if result['reliability_score'] >= case['expected_min_score']:
            print("âœ… ã‚¹ã‚³ã‚¢åˆ¤å®š: æˆåŠŸ")
        else:
            print("âŒ ã‚¹ã‚³ã‚¢åˆ¤å®š: å¤±æ•—")

def test_reliability_sorting():
    """ä¿¡é ¼æ€§ã«ã‚ˆã‚‹ä¸¦ã³æ›¿ãˆæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ“Š ä¿¡é ¼æ€§ä¸¦ã³æ›¿ãˆæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)

    from main import SearchResult, DeepResearch

    # ãƒ†ã‚¹ãƒˆç”¨ã®æ¤œç´¢çµæœã‚’ä½œæˆ
    test_results = [
        SearchResult(
            title="ä½ä¿¡é ¼æ€§è¨˜äº‹",
            url="https://blog.example.com/low.html",
            snippet="ä½ä¿¡é ¼æ€§ã®å†…å®¹",
            search_query="ãƒ†ã‚¹ãƒˆ",
            reliability_score=0.3,
            source_type="blog"
        ),
        SearchResult(
            title="é«˜ä¿¡é ¼æ€§è¨˜äº‹",
            url="https://www.gov.jp/high.html",
            snippet="é«˜ä¿¡é ¼æ€§ã®å†…å®¹",
            search_query="ãƒ†ã‚¹ãƒˆ",
            reliability_score=0.9,
            source_type="official"
        ),
        SearchResult(
            title="ä¸­ä¿¡é ¼æ€§è¨˜äº‹",
            url="https://news.example.com/medium.html",
            snippet="ä¸­ä¿¡é ¼æ€§ã®å†…å®¹",
            search_query="ãƒ†ã‚¹ãƒˆ",
            reliability_score=0.6,
            source_type="news"
        )
    ]

    # DeepResearchã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
    researcher = DeepResearch("gemini")

    # ä¸¦ã³æ›¿ãˆå‰
    print("ä¸¦ã³æ›¿ãˆå‰:")
    for i, result in enumerate(test_results, 1):
        print(f"{i}. {result.title} (ä¿¡é ¼æ€§: {result.reliability_score:.2f})")

    # ä¸¦ã³æ›¿ãˆå¾Œ
    sorted_results = researcher._sort_results_by_reliability(test_results)
    print("\nä¸¦ã³æ›¿ãˆå¾Œ:")
    for i, result in enumerate(sorted_results, 1):
        print(f"{i}. {result.title} (ä¿¡é ¼æ€§: {result.reliability_score:.2f})")

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
    filtered_results = researcher._filter_results_by_reliability(test_results, threshold=0.5)
    print(f"\nãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œ (é–¾å€¤: 0.5): {len(filtered_results)}ä»¶")
    for i, result in enumerate(filtered_results, 1):
        print(f"{i}. {result.title} (ä¿¡é ¼æ€§: {result.reliability_score:.2f})")

    # æ¤œè¨¼
    if sorted_results[0].reliability_score == 0.9:
        print("âœ… ä¸¦ã³æ›¿ãˆæ©Ÿèƒ½: æˆåŠŸ")
    else:
        print("âŒ ä¸¦ã³æ›¿ãˆæ©Ÿèƒ½: å¤±æ•—")

    if len(filtered_results) == 2:
        print("âœ… ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½: æˆåŠŸ")
    else:
        print("âŒ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½: å¤±æ•—")

if __name__ == "__main__":
    test_additional_queries()
    test_date_extraction()
    test_hallucination_prevention()
    test_markdown_links()
    test_integrated_report()
    test_date_relative_analysis()
    test_date_integration()
    test_enhanced_date_extraction()
    test_academic_quality_prompts()
    test_reliability_evaluation()
    test_reliability_sorting()
